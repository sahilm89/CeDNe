{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedne import utils\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import pywt\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import partial_tucker\n",
    "from tensorly.tenalg import multi_mode_dot\n",
    "from tensorly import kruskal_to_tensor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cross_corr(n1,n2, window=(0,-1,1)):\n",
    "    start, end, step = window\n",
    "    return np.corrcoef(n1[start:end:step], n2[start:end:step])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoising(signal, wavelet='db4', level=4, threshold_factor=1.):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, mode='symmetric', level=level)\n",
    "    \n",
    "    # Estimate the universal threshold (Median Absolute Deviation)\n",
    "    sigma = np.median(np.abs(coeffs[-level])) / 0.6745  \n",
    "    threshold = threshold_factor * sigma * np.sqrt(2 * np.log(len(signal)))\n",
    "    \n",
    "    # Apply thresholding\n",
    "    coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]\n",
    "    denoised_signal = pywt.waverec(coeffs, wavelet, mode='symmetric')\n",
    "    \n",
    "    return denoised_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleaxis(axes, every=False, outward=False):\n",
    "    if not isinstance(axes, (list, np.ndarray)):\n",
    "        axes = [axes]\n",
    "    for ax in axes:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        if (outward):\n",
    "            ax.spines['bottom'].set_position(('outward', 10))\n",
    "            ax.spines['left'].set_position(('outward', 10))\n",
    "        if every:\n",
    "            ax.spines['bottom'].set_visible(False)\n",
    "            ax.spines['left'].set_visible(False)\n",
    "        ax.get_xaxis().tick_bottom()\n",
    "        ax.get_yaxis().tick_left()\n",
    "        ax.set_title('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = {}\n",
    "for js in os.listdir('/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/'):\n",
    "    with open (\"/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/{}\".format(js), 'r') as f:\n",
    "        jsons['Atanas et al (2023) ' +  js] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = utils.makeWorm('atanas')\n",
    "nn = w.networks['Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mat = utils.loadSynapticWeights(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measuredNeurons = {}\n",
    "neuron_labels = []\n",
    "for js, p in jsons.items():\n",
    "    sortedKeys = sorted ([int(x) for x in (p['labeled'].keys())])\n",
    "    labelledNeurons = {p['labeled'][str(x)]['label']:x for x in sortedKeys if not '?' in p['labeled'][str(x)]['label']} # Removing unsure hits\n",
    "    measuredNeurons[js] = {m:i for i,m in enumerate(set(labelledNeurons))}\n",
    "    neuron_labels+=measuredNeurons[js].keys()\n",
    "neuron_labels = sorted(set(neuron_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons.keys()\n",
    "database = 'Atanas et al (2023) 2022-06-14-01.json'\n",
    "num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][neuron_labels[20]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron in nn.neurons:\n",
    "    if neuron in measuredNeurons[database]: \n",
    "        nn.neurons[neuron].set_property('amplitude', jsons[database]['trace_array'][measuredNeurons[database][neuron]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_window_correlation(database, window_sizes=range(5,50,10), num_samples=100):\n",
    "    by_window = {}\n",
    "    #steps = range(0,num_timepoints,t_step)\n",
    "    for window_size in window_sizes:\n",
    "        steps = sorted(np.random.randint(0, num_timepoints - window_size, num_samples))\n",
    "        num_steps = len(steps)\n",
    "        corr_window = np.empty((len(neuron_labels), len(neuron_labels)))\n",
    "        corr_window[:] = np.nan\n",
    "        for i,n1 in enumerate(neuron_labels):\n",
    "            for j in range(i+1, len(neuron_labels)):\n",
    "                n2 = neuron_labels[j]\n",
    "                if n1 in measuredNeurons[database] and n2 in measuredNeurons[database]:\n",
    "                    corr_window[i,j] = 0.\n",
    "                    for tstart in steps:\n",
    "                        window = (tstart,tstart+window_size,1)\n",
    "                        corr_window[i,j] += calculate_cross_corr(jsons[database]['trace_array'][measuredNeurons[database][n1]], jsons[database]['trace_array'][measuredNeurons[database][n2]], window=window)\n",
    "        corr_window/=num_steps\n",
    "        by_window[window_size] = corr_window\n",
    "    return by_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_sizes=range(1,250,25)\n",
    "# by_database = {}\n",
    "# for database in jsons.keys():\n",
    "#     by_database[database] = return_window_correlation(database=database, window_sizes=window_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_by_database = np.nanmean(np.stack([by_database[database][window_sizes[5]] for database in list(jsons.keys())]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(24,24))\n",
    "# cbar = ax.pcolor(avg_by_database, vmin=-1, vmax=1, cmap='PuOr')\n",
    "# ax.set_yticks(np.arange(len(neuron_labels))+0.5, neuron_labels)\n",
    "# ax.set_xticks(np.arange(len(neuron_labels))+0.5, neuron_labels, rotation=45, ha='right')\n",
    "# plt.colorbar(cbar)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(24,24))\n",
    "# cbar = ax.pcolor(np.tril(avg_by_database,k=-1), vmin=-1, vmax=1, cmap='PuOr')\n",
    "# ax.set_yticks(np.arange(len(neuron_labels))+0.5, neuron_labels)\n",
    "# ax.set_xticks(np.arange(len(neuron_labels))+0.5, neuron_labels, rotation=45, ha='right')\n",
    "# plt.colorbar(cbar)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr_thres in np.linspace(0,1,10):\n",
    "    connected_syn = []\n",
    "    connected_all = []\n",
    "    xind, yind = np.where(np.abs(np.tril(avg_by_database,k=-1))>corr_thres)\n",
    "    if len(xind):\n",
    "        for (x,y) in zip(xind, yind):\n",
    "            connected_all.append(tuple(sorted([neuron_labels[x], neuron_labels[y]])))\n",
    "            if (nn.neurons[neuron_labels[x]], nn.neurons[neuron_labels[y]],0) in nn.connections.connections or (nn.neurons[neuron_labels[y]], nn.neurons[neuron_labels[x]],0) in nn.connections.connections:\n",
    "                connected_syn.append(tuple(sorted([neuron_labels[x], neuron_labels[y]])))\n",
    "        print(corr_thres, len(set(connected_syn))/len(connected_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr, minLength = {x:[] for x in range(1,7)},  []\n",
    "# for x in range(np.shape(avg_by_database)[0]):\n",
    "#     for y in range(x+1,np.shape(avg_by_database)[1]):\n",
    "#         minLength.append(np.min([utils.nx.shortest_path_length(nn, nn.neurons[neuron_labels[x]], nn.neurons[neuron_labels[y]]), utils.nx.shortest_path_length(nn, nn.neurons[neuron_labels[y]], nn.neurons[neuron_labels[x]])]))\n",
    "#         corr[minLength[-1]].append(avg_by_database[x,y])\n",
    "\n",
    "# f, ax = plt.subplots()\n",
    "# for k in corr.keys():\n",
    "#     ax.scatter(np.nanmean(corr[k]), k)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr_thres = 0.25\n",
    "# avg_by_database [np.where(np.abs(avg_by_database)<corr_thres)] = np.nan\n",
    "# f, ax = plt.subplots(figsize=(24,24))\n",
    "# cbar = ax.pcolor(avg_by_database, vmin=-1, vmax=1, cmap='PuOr')\n",
    "# ax.set_yticks(np.arange(len(neuron_labels))+0.5, neuron_labels)\n",
    "# ax.set_xticks(np.arange(len(neuron_labels))+0.5, neuron_labels, rotation=45, ha='right')\n",
    "# plt.colorbar(cbar)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(avg_by_database>corr_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_corr = []\n",
    "# for window_size in window_sizes:\n",
    "#     avg_corr_by_window = []\n",
    "#     for database in jsons.keys():\n",
    "#         avg_corr_by_window.append(np.nanmean(np.abs(np.tril(by_database[database][window_size],k=-1))))\n",
    "#     avg_corr.append(np.mean(avg_corr_by_window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.array(window_sizes)*jsons[database]['avg_timestep'], avg_corr)\n",
    "# plt.xlabel(\"Time (mins)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(window_sizes[np.argmax(avg_corr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(window_sizes[np.argmax(avg_corr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worms = jsons.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_var = []\n",
    "for worm in list(worms)[:1]:\n",
    "    for key in jsons[worm].keys():\n",
    "        if isinstance(jsons[worm][key], list):\n",
    "            if len(jsons[worm][key]) == jsons[worm]['max_t']:\n",
    "                behav_var.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_var.append('head_frequency')\n",
    "behav_var.append('acceleration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncounts = {neuron: 0 for neuron in neuron_labels}\n",
    "nthres = 8\n",
    "for database in jsons:\n",
    "    for neuron in measuredNeurons[database]:\n",
    "        ncounts[neuron]+=1\n",
    "    \n",
    "print(ncounts, len(ncounts))\n",
    "popns = [n for n in ncounts if ncounts[n]<nthres]\n",
    "_ = [ncounts.pop(p) for p in popns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlabels = list(ncounts.keys())\n",
    "type_list = ['sensory', 'interneuron', 'motorneuron']\n",
    "nindices = []\n",
    "for ty in type_list:\n",
    "    for n in nn.neurons:\n",
    "        if nn.neurons[n].type == ty and n in nlabels:\n",
    "            nindices.append(list(nlabels).index(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_factor = 1.47\n",
    "rank = 20\n",
    "method = 'parafac'\n",
    "full_tensor = np.empty((len(jsons), len(nlabels), num_timepoints))\n",
    "worms = list(jsons.keys())\n",
    "for i,worm in enumerate(worms):\n",
    "    for j,n in enumerate(nlabels):\n",
    "        if n in measuredNeurons[worm]:\n",
    "            full_tensor[i,j,:] = wavelet_denoising(jsons[worm]['trace_array'][measuredNeurons[worm][n]][:num_timepoints], wavelet='db6', level=2, threshold_factor=threshold_factor)\n",
    "\n",
    "if method == 'parafac':\n",
    "    weights, factors = parafac(full_tensor, rank=rank, init='random', n_iter_max=100)\n",
    "    imputed_tensor = kruskal_to_tensor((weights, factors))\n",
    "    #best_core, best_factors = tucker(imputed_tensor, rank=rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It looks like 100 points (1 minute) is enough to capture max correlations. Making a Hankel matrix at 100 points, with delays and then a 4D tensor that contains all this delay embedding in a fresh dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hankel_matrix(tensor, k):\n",
    "    W, N, T = tensor.shape\n",
    "    T_2 = T - k + 1\n",
    "    \n",
    "    # Initialize the resulting tensor with zeros\n",
    "    hankel_tensor = np.zeros((W, N, T_2, k))\n",
    "    \n",
    "    # Populate the hankel_tensor\n",
    "    for w in range (W):\n",
    "        for n in range(N):\n",
    "            for t_2 in range(T_2):\n",
    "                hankel_tensor[w, n, t_2, :] = tensor[w, n, t_2:t_2 + k]\n",
    "    \n",
    "    return hankel_tensor\n",
    "\n",
    "\n",
    "def moving_window_average(vector, window_size, step_size):\n",
    "    n = len(vector)\n",
    "    averages = []\n",
    "    \n",
    "    for start in range(0, n - window_size + 1, step_size):\n",
    "        window = vector[start:start + window_size]\n",
    "        window_avg = np.mean(window)\n",
    "        averages.append(window_avg)\n",
    "    \n",
    "    return np.array(averages)\n",
    "\n",
    "def explained_variance(true_tensor, core, factors):\n",
    "    reconstructed = tl.tenalg.multi_mode_dot(core, factors)\n",
    "    total_variance = tl.norm(true_tensor, 2) ** 2\n",
    "    explained_var = tl.norm(reconstructed, 2) ** 2 / total_variance\n",
    "    return explained_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25 #100 \n",
    "\n",
    "t_rank = window_size #10 \n",
    "n_rank = 15 #10 \n",
    "d_rank = num_timepoints - window_size +1\n",
    "w_rank = len(jsons.keys())\n",
    "\n",
    "# Define a grid of ranks\n",
    "rank_grid = {\n",
    "    'w_rank': w_rank,\n",
    "    'n_rank': n_rank,\n",
    "    'd_rank': d_rank,\n",
    "    't_rank': t_rank\n",
    "}\n",
    "\n",
    "core_worms = {}\n",
    "factor_worms = {}\n",
    "#for worm, wormname in zip(imputed_tensor, jsons.keys()):\n",
    "#    hankel_transformed_tensor = create_hankel_matrix(worm, window_size)\n",
    "hankel_transformed_tensor = create_hankel_matrix(imputed_tensor, window_size)\n",
    "X = tl.tensor(hankel_transformed_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [\n",
    "        rank_grid['w_rank'], \n",
    "        rank_grid['n_rank'], \n",
    "        rank_grid['d_rank'],\n",
    "        rank_grid['t_rank']\n",
    "        ]\n",
    "best_core, best_factors = tucker(X, rank=ranks)\n",
    "#core_worms[wormname] = best_core\n",
    "#factor_worms[wormname] = best_factors\n",
    "explained_vars = explained_variance(hankel_transformed_tensor, best_core, best_factors)\n",
    "print(explained_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_factors[1].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_num = 1\n",
    "# for worm in jsons.keys():\n",
    "#best_core, best_factors = core_worms[worm], factor_worms[worm]\n",
    "# f, ax = plt.subplots(figsize=(2*10,10), layout='constrained', nrows=ranks[factor_num])\n",
    "for j,fac in enumerate(best_factors[factor_num].T[:10]):\n",
    "    # if factor_num == 0:\n",
    "    #     f, ax = plt.subplots(figsize=(24,3), layout='constrained')\n",
    "    #     ax.plot(fac)\n",
    "    #     ax.set_xticks(np.arange(len(best_factors[0])), np.arange(len(best_factors[0]))+1)\n",
    "    #     simpleaxis(ax)\n",
    "    #     plt.show()\n",
    "    if factor_num == 1:\n",
    "        f, ax = plt.subplots(figsize=(24,3), layout='constrained')\n",
    "        ax.plot(fac)\n",
    "        ax.set_xticks(range(len(nlabels)), nlabels, rotation=45)\n",
    "        simpleaxis(ax)\n",
    "        plt.show()\n",
    "    if factor_num == 2:\n",
    "        # f, ax = plt.subplots(figsize=(24,3), layout='constrained')\n",
    "        ax[j].plot(fac)\n",
    "        ax[j].set_xticks(np.arange(0,len(best_factors[factor_num]),10),np.arange(0,len(best_factors[factor_num]),10), rotation=45)\n",
    "        # simpleaxis(ax)\n",
    "        # plt.show()\n",
    "    if factor_num == 3:\n",
    "        # f, ax = plt.subplots(figsize=(3,2), layout='constrained')\n",
    "        ax[j].plot(np.arange(window_size)*jsons[database]['avg_timestep'], fac)\n",
    "        ax[j].set_xticks(np.linspace(0,len(best_factors[factor_num])*jsons[database]['avg_timestep'],2))\n",
    "simpleaxis(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_data = tl.tenalg.multi_mode_dot(best_core, best_factors, skip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6,12), layout='constrained')\n",
    "cbar = ax.pcolor(best_factors[1])\n",
    "ax.set_xticks(np.arange(n_rank)+0.5, np.arange(n_rank)+1)\n",
    "ax.set_yticks(np.arange(len(nlabels))+0.5, nlabels)\n",
    "simpleaxis(ax)\n",
    "f.colorbar(cbar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find where the cutoff for component weight crosses 90% of the CDF\n",
    "cutoff = 0.75\n",
    "hist = np.histogram(np.abs(best_factors[1].ravel()), bins=np.linspace(0,0.35,30), density=True)\n",
    "\n",
    "cdf = np.cumsum(hist[0])\n",
    "cdf/=cdf[-1]\n",
    "for i in range(len(cdf)):\n",
    "    if cdf[i] >= cutoff:\n",
    "        break\n",
    "thres = hist[1][i]\n",
    "print(thres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thres = 0.145\n",
    "# cutoff = 0.9\n",
    "f, ax = plt.subplots(figsize=(1.5,1.5))\n",
    "ax.hist(np.abs(best_factors[1].ravel()), bins=np.linspace(0,0.35,30), color='gray', cumulative=True, density=True)\n",
    "ax.axvline(thres, color='red', ls='--')\n",
    "ax.axhline(cutoff, color='red', ls='--')\n",
    "ax.set_ylabel(\"Cumulative Density\")\n",
    "ax.set_xlabel(\"Component weight\")\n",
    "simpleaxis(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fac in best_factors[1].T:\n",
    "    f, ax = plt.subplots(figsize=(1,1), layout='constrained')\n",
    "    ax.hist(np.abs(fac), bins=np.linspace(0,0.3,25), color='gray')\n",
    "    ax.axvline(thres, color='red', ls='--')\n",
    "    simpleaxis(ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlabels_by_factor = []\n",
    "for fac in best_factors[1].T:\n",
    "    nlabels_by_factor.append([nlabels[j[0]] for j in np.argwhere(np.abs(fac)>thres)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in (enumerate(nlabels_by_factor)):\n",
    "    print(f\"{i}: {len(j)}: {j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subnet_arr = {}\n",
    "for j in range(len(nlabels_by_factor)):\n",
    "    print(j)\n",
    "    subnet_arr[j] = nn.subnetwork(neuron_names=nlabels_by_factor[j], name=f\"component_{j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6,12), layout='constrained')\n",
    "cbar = ax.pcolor(best_factors[1])\n",
    "ax.set_xticks(np.arange(n_rank)+0.5, np.arange(n_rank)+1)\n",
    "ax.set_yticks(np.arange(len(nlabels))+0.5, nlabels)\n",
    "simpleaxis(ax)\n",
    "f.colorbar(cbar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(nlabels_by_factor)):\n",
    "    print(j)\n",
    "    utils.plot_spiral(subnet_arr[j], figsize=(5,5), save=f'./tucker-decomposition-hankel/spiral_neuron_component_{window_size}-{j}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_convolved = np.zeros((projected_data.shape[0], projected_data.shape[1], projected_data.shape[2]+projected_data.shape[3]-1))\n",
    "for ind in range(projected_data.shape[1]):\n",
    "    for j in range(projected_data.shape[0]):\n",
    "        for k in range(projected_data.shape[2]):\n",
    "            projected_convolved[j,ind,k:k+projected_data.shape[3]] += projected_data[j,ind,k,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalized_cross_correlation(activity, behavior):\n",
    "#     # Compute raw cross-correlation\n",
    "#     raw_corr = np.correlate(activity, behavior, mode='full')\n",
    "    \n",
    "#     # Lengths of signals\n",
    "#     n = len(activity)\n",
    "#     m = len(behavior)\n",
    "    \n",
    "#     # Precompute sums of squares for normalization\n",
    "#     activity_energy = np.sum(activity ** 2)\n",
    "#     behavior_energy= np.sum(behavior ** 2)\n",
    "    \n",
    "#     # Normalize each lag\n",
    "#     norm_corr = raw_corr / np.sqrt(activity_energy * behavior_energy)\n",
    "    \n",
    "#     # Remove any NaN values (if behavior_energy is zero in some regions)\n",
    "#     norm_corr = np.nan_to_num(norm_corr)\n",
    "    \n",
    "#     return norm_corr\n",
    "from scipy.signal import correlate\n",
    "def normalized_cross_correlation(activity, behavior, lag_min=-50, lag_max=50):\n",
    "    raw_corr = np.correlate(activity, behavior, mode='full')\n",
    "\n",
    "    # Generate all possible lags\n",
    "    lags = np.arange(-len(activity) + 1, len(behavior))\n",
    "\n",
    "    # Restrict to the specified lag range\n",
    "    valid_lag_indices = (lags >= lag_min) & (lags <= lag_max)\n",
    "    restricted_corr = raw_corr[valid_lag_indices]\n",
    "    restricted_lags = lags[valid_lag_indices]\n",
    "\n",
    "    # Normalize for each lag\n",
    "    norm_corr = []\n",
    "    for lag in restricted_lags:\n",
    "        # Calculate the overlapping segments\n",
    "        if lag < 0:  # behavior leads activity\n",
    "            overlap_activity = activity[-lag:]\n",
    "            overlap_behavior = behavior[:len(activity) + lag]\n",
    "        else:  # activity leads behavior\n",
    "            overlap_activity = activity[:len(behavior) - lag]\n",
    "            overlap_behavior = behavior[lag:]\n",
    "\n",
    "        # Compute energy and normalize\n",
    "        activity_energy = np.sum(overlap_activity ** 2)\n",
    "        behavior_energy = np.sum(overlap_behavior ** 2)\n",
    "        norm_factor = np.sqrt(activity_energy * behavior_energy)\n",
    "\n",
    "        if norm_factor > 0:\n",
    "            norm_corr.append(restricted_corr[np.where(restricted_lags == lag)[0][0]] / norm_factor)\n",
    "        else:\n",
    "            norm_corr.append(0)\n",
    "    return norm_corr, restricted_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rate of change of sensory stream? Velocity calculation? Successive feedforward loop motifs. Acceleration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moving_window_zero_crossing_frequency_same_length(time_array, direction_array, window_size):\n",
    "    \"\"\"\n",
    "    Calculate zero-crossing frequency with a moving window, returning an array of the same length.\n",
    "\n",
    "    Parameters:\n",
    "    - time_array: 1D NumPy array of time values.\n",
    "    - direction_array: 1D NumPy array of head direction values.\n",
    "    - window_size: Window size in seconds.\n",
    "\n",
    "    Returns:\n",
    "    - A NumPy array of zero-crossing frequencies, same length as the input arrays.\n",
    "    \"\"\"\n",
    "    # Ensure arrays are sorted by time\n",
    "    sorted_indices = np.argsort(time_array)\n",
    "    time_array = time_array[sorted_indices]\n",
    "    direction_array = direction_array[sorted_indices]\n",
    "    \n",
    "    # Calculate zero crossings\n",
    "    zero_crossings = np.diff(np.sign(direction_array)) != 0\n",
    "    zero_crossings = np.insert(zero_crossings, 0, False)  # Pad to match original array length\n",
    "    \n",
    "    # Compute half-window size in terms of indices\n",
    "    half_window = int(window_size / 2 / np.mean(np.diff(time_array)))  # Convert seconds to indices\n",
    "    \n",
    "    # Initialize result array\n",
    "    frequencies = np.zeros_like(time_array, dtype=float)\n",
    "    \n",
    "    for i in range(len(time_array)):\n",
    "        # Define the window range (clamp to array bounds)\n",
    "        start_idx = max(0, i - half_window)\n",
    "        end_idx = min(len(time_array), i + half_window)\n",
    "        \n",
    "        # Count zero crossings in the window\n",
    "        zero_crossing_count = np.sum(zero_crossings[start_idx:end_idx])\n",
    "        \n",
    "        # Calculate frequency (bobs per second)\n",
    "        window_duration = time_array[end_idx - 1] - time_array[start_idx]\n",
    "        frequencies[i] = zero_crossing_count / window_duration if window_duration > 0 else 0\n",
    "\n",
    "    return frequencies\n",
    "\n",
    "def calculate_acceleration(velocity_array, time_array, window_size=5):\n",
    "    \"\"\"\n",
    "    Calculate acceleration from velocity data and smooth it using a Gaussian filter.\n",
    "\n",
    "    Parameters:\n",
    "    - velocity_array: 1D NumPy array of velocity values.\n",
    "    - time_array: 1D NumPy array of time values.\n",
    "    - smoothing_sigma: Standard deviation for Gaussian kernel (higher = more smoothing).\n",
    "\n",
    "    Returns:\n",
    "    - A NumPy array of smoothed acceleration values, same length as the input arrays.\n",
    "    \"\"\"\n",
    "    # Ensure the arrays are sorted by time\n",
    "    sorted_indices = np.argsort(time_array)\n",
    "    time_array = time_array[sorted_indices]\n",
    "    velocity_array = velocity_array[sorted_indices]\n",
    "    \n",
    "    # Calculate differences in velocity and time\n",
    "    dv = np.diff(velocity_array, prepend=velocity_array[0])\n",
    "    dt = np.diff(time_array, prepend=time_array[0])\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    dt[dt == 0] = np.nan\n",
    "    \n",
    "    # Compute acceleration (dv/dt)\n",
    "    acceleration = dv / dt\n",
    "    \n",
    "    # Handle edge cases (e.g., divide by zero leading to NaN at first index)\n",
    "    acceleration[0] = acceleration[1] if len(acceleration) > 1 else 0\n",
    "    \n",
    "    # Smooth acceleration using a Gaussian filter\n",
    "    #smoothed_acceleration = gaussian_filter1d(acceleration, sigma=smoothing_sigma)\n",
    "    smoothed_acceleration = np.convolve(acceleration, np.ones(window_size) / window_size, mode='same')\n",
    "    \n",
    "    return smoothed_acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, worm in enumerate(worms):\n",
    "    beh = 'head_curvature'\n",
    "    time = np.linspace(0, jsons[worm]['max_t'], len(jsons[worm][beh]))[:projected_convolved.shape[2]]\n",
    "    head_freq = calculate_moving_window_zero_crossing_frequency_same_length(time, np.array(jsons[worm][beh]), 25)\n",
    "    plt.plot(jsons[worm][beh], color='gray')\n",
    "    plt.plot(head_freq, color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, worm in enumerate(worms):\n",
    "    time = np.linspace(0, jsons[worm]['max_t'], len(jsons[worm]['head_curvature']))[:projected_convolved.shape[2]]\n",
    "    jsons[worm]['head_frequency'] = calculate_moving_window_zero_crossing_frequency_same_length(time, np.array(jsons[worm]['head_curvature'])[:projected_convolved.shape[2]], window_size)\n",
    "\n",
    "    time = np.linspace(0, jsons[worm]['max_t'], len(jsons[worm]['velocity']))[:projected_convolved.shape[2]]\n",
    "    jsons[worm]['acceleration'] = calculate_acceleration(np.array(jsons[worm]['velocity'])[:projected_convolved.shape[2]], time, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behav_activity = {b: [] for b in behav_var}\n",
    "for j, worm in enumerate(worms):\n",
    "    f, ax = plt.subplots(figsize=(12,(1+len(behav_var))*2), layout='constrained', nrows=len(behav_var)+1)\n",
    "    for ind in range(projected_data.shape[1]):\n",
    "        ax[0].plot(projected_convolved[j,ind,:])\n",
    "        simpleaxis(ax[0])\n",
    "    mapping = {}\n",
    "    for k,beh in enumerate(behav_var):\n",
    "        time = np.linspace(0, jsons[worm]['max_t'], len(jsons[worm][beh]))[:projected_convolved.shape[2]]\n",
    "        corr_ind = []\n",
    "        for ind in range(projected_data.shape[1]):\n",
    "            corr_ind.append(np.corrcoef(projected_convolved[j,ind,:], jsons[worm][beh][:projected_convolved.shape[2]])[0,1])\n",
    "        ax[k+1].plot(time, jsons[worm][beh][:projected_convolved.shape[2]], color='#4A90E2')\n",
    "        ax1 = ax[k+1].twinx()\n",
    "\n",
    "        # Compute cross-correlation\n",
    "        behavior = np.array(jsons[worm][beh][:projected_convolved.shape[2]])\n",
    "        behavior_std = np.std(behavior)\n",
    "        best_match = None\n",
    "        best_score = -np.inf\n",
    "        best_lag = 0\n",
    "        for ind in range(projected_data.shape[1]):\n",
    "            activity = projected_convolved[j,ind,:]\n",
    "            \n",
    "            # corr = correlate(activity, behavior, mode='full')\n",
    "\n",
    "            # # Normalize cross-correlation\n",
    "            # activity_std = np.std(activity)\n",
    "            # norm_factor = len(activity) * len(behavior) * activity_std * behavior_std\n",
    "            # normalized_corr = corr / norm_factor\n",
    "\n",
    "            normalized_corr, all_lags = normalized_cross_correlation(activity, behavior)\n",
    "            # Find the best lag\n",
    "            # all_lags = np.arange(-len(activity) + 1, len(behavior))\n",
    "            lag = all_lags[np.argmax(np.abs(normalized_corr))]\n",
    "            score = np.abs(normalized_corr[np.argmax(np.abs(normalized_corr))])\n",
    "            actual_corr = normalized_corr[np.argmax(np.abs(normalized_corr))]\n",
    "            \n",
    "            # Update best match\n",
    "            if score > best_score:\n",
    "                best_match = ind\n",
    "                best_score = score\n",
    "                best_lag = lag\n",
    "                best_corr = actual_corr\n",
    "        \n",
    "            # Assign best match\n",
    "        mapping[k] = (best_match, best_lag, best_corr)\n",
    "\n",
    "        # ax1.plot(time, projected_convolved[j, np.argmax(corr_ind), :], color='#F5A623')\n",
    "        ax1.plot(time, projected_convolved[j, best_match, :], color='#F5A623')\n",
    "        simpleaxis(ax[k+1])\n",
    "        # ax[k+1].set_title(f\"{beh}, {np.argmax(corr_ind)}, {max(corr_ind)}\")\n",
    "        ax[k+1].set_title(f\"{beh}, {mapping[k]}\")\n",
    "        if best_score>0.7:\n",
    "            behav_activity[beh].append(best_match)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "f, ax = plt.subplots(ncols= len(behav_var), figsize=((len(behav_var))*2, 2), layout='constrained', sharex=True, sharey=True)\n",
    "for k,beh in enumerate(behav_var):\n",
    "    c = Counter(behav_activity[beh])\n",
    "    clist, cbar = zip(*c.items())\n",
    "    ax[k].bar(clist, cbar)\n",
    "    simpleaxis(ax[k])\n",
    "    ax[k].set_title(beh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1 = 2\n",
    "ind2 = 4\n",
    "f, ax = plt.subplots(figsize=(4,12), layout='constrained', ncols=2, sharex=True, sharey=True)\n",
    "ax[0].pcolor(np.mean(projected_data[:,:,ind1,:], axis=0))\n",
    "ax[1].pcolor(np.mean(projected_data[:,:,ind2,:], axis=0))\n",
    "simpleaxis(ax)\n",
    "ax[0].set_yticks(np.arange(len(nlabels))+0.5, nlabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(measuredNeurons[database].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 'AWCL'\n",
    "f, ax = plt.subplots(figsize=(12,2))\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(jsons[database]['velocity'][:-1], color='gray')\n",
    "ax.plot(moving_window_average(np.diff(jsons[database]['trace_array'][measuredNeurons[database][neuron]],1), 1,1), color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(jsons[database]['velocity'][:-10], moving_window_average(np.diff(jsons[database]['trace_array'][measuredNeurons[database][neuron]],1), 10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.5\n",
    "mpro = np.mean(projected_data[:,:,ind,:50], axis=0)\n",
    "print([nlabels[n] for n in sorted(set(np.where(np.abs(mpro)>thres)[0]))])\n",
    "mpro = np.mean(projected_data[:,:,ind+1,50:], axis=0)\n",
    "print([nlabels[n] for n in sorted(set(np.where(np.abs(mpro)>thres)[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.neurons['RMDL'].get_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 69\n",
    "np.corrcoef(best_factors[factor_num].T[4][ind:], best_factors[factor_num].T[3][:-ind])[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 0\n",
    "step=50\n",
    "trace_grid_space = 1\n",
    "nlabs_newind = [list(nlabels)[i] for i in nindices]\n",
    "# for j,w in enumerate(worms):\n",
    "    # if j<2:\n",
    "        #best_core, best_factors = core_worms[worm], factor_worms[worm]\n",
    "projected_data = tl.tenalg.multi_mode_dot(best_core, best_factors, skip=2)\n",
    "f = plt.figure(figsize=(12,12), layout='constrained')\n",
    "gs = matplotlib.gridspec.GridSpec(len(behav_var)+1,1, figure = f, height_ratios=[30]*1 + [1]*len(behav_var))\n",
    "ax = f.add_subplot(gs[:trace_grid_space, 0])\n",
    "vm = np.max(np.abs(projected_data[:,:,:,comp]))\n",
    "red_time = np.arange(projected_data[:,:,:,comp].shape[1])\n",
    "real_time = np.linspace(0,jsons[w]['max_t'], projected_data[:,:,:,comp].shape[1])\n",
    "proj_mat = projected_data[:,nindices,:,comp]\n",
    "ax.imshow(proj_mat, extent=(0, jsons[w]['max_t'], 0, len(nindices)), cmap='PuOr', vmin=-vm, vmax=vm, aspect='auto', origin='lower')\n",
    "xticks_real = real_time[::step]\n",
    "xticks_red = red_time[::step]\n",
    "ax.grid(True, axis='x', which='both')\n",
    "simpleaxis(ax)\n",
    "ax.set_xticks(xticks_real)\n",
    "ax.set_yticks(np.arange(projected_data.shape[0])+0.5)\n",
    "ax.set_yticklabels(nlabs_newind)\n",
    "# for n in range(projected_data.shape[1]):\n",
    "#     ax.plot(real_time, (n+100)*projected_data[j,n,:,comp])\n",
    "#     xticks = real_time[::step]\n",
    "#ax.set_xticks(xticks, [f\"{x:.0f}\" for x in xticks])\n",
    "for k,beh in enumerate(behav_var):\n",
    "    ax1 = f.add_subplot(gs[trace_grid_space+k:trace_grid_space+k+1, 0], sharex=ax)\n",
    "    time = np.linspace(0, jsons[w]['max_t'], len(jsons[w][beh]))\n",
    "    ax1.plot(time, jsons[w][beh])\n",
    "    # ax1.set_xticks([])\n",
    "    simpleaxis(ax1)\n",
    "    ax1.set_title(beh)\n",
    "    ax1.grid(True, axis='x')\n",
    "#ax1.set_xticks(time)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = 0\n",
    "step=50\n",
    "trace_grid_space = 1\n",
    "nlabs_newind = [list(nlabels)[i] for i in nindices]\n",
    "for j,w in enumerate(worms):\n",
    "    if j<2:\n",
    "        f = plt.figure(figsize=(12,12), layout='constrained')\n",
    "        gs = matplotlib.gridspec.GridSpec(len(behav_var)+projected_data.shape[1],1, figure = f, height_ratios=[1]*projected_data.shape[1] + [1]*len(behav_var))\n",
    "        vm = np.max(np.abs(projected_data[j,:,:,comp]))\n",
    "        red_time = np.arange(projected_data[j,:,:,comp].shape[1])\n",
    "        real_time = np.linspace(0,jsons[w]['max_t'], projected_data[j,:,:,comp].shape[1])\n",
    "        proj_mat = projected_data[j,:,:,comp]\n",
    "        for l,p in enumerate(proj_mat):\n",
    "            ax = f.add_subplot(gs[l:l+1, 0], sharex=ax)\n",
    "            ax.plot(p)\n",
    "            ax.grid(True, axis='x', which='both')\n",
    "            simpleaxis(ax)\n",
    "            xticks_real = real_time[::step]\n",
    "            ax.set_xticks(xticks_real)\n",
    "            ax.set_title(f\"proj{l+1}\")\n",
    "        for k,beh in enumerate(behav_var):\n",
    "            ax1 = f.add_subplot(gs[projected_data.shape[1]+k:projected_data.shape[1]+k+1, 0], sharex=ax)\n",
    "            time = np.linspace(0, jsons[w]['max_t'], len(jsons[w][beh]))\n",
    "            ax1.plot(time, jsons[w][beh])\n",
    "            # ax1.set_xticks([])\n",
    "            simpleaxis(ax1)\n",
    "            ax1.set_title(beh)\n",
    "            ax1.grid(True, axis='x')\n",
    "        #ax1.set_xticks(time)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_thres = 0.9\n",
    "for comp in range(2,n_rank):\n",
    "    for wind,w in enumerate(worms):\n",
    "        best_core, best_factors = core_worms[worm], factor_worms[worm]\n",
    "        projected_data = tl.tenalg.multi_mode_dot(best_core, best_factors, skip=2)\n",
    "        proj_mat = projected_data[:,:,comp]\n",
    "        for i,p in enumerate(proj_mat):\n",
    "            for j,b in enumerate(behav_var):\n",
    "                corr_np = np.corrcoef(p,moving_window_average(jsons[w][b][:num_timepoints], window_size, 1))[0,1]\n",
    "                if np.abs(corr_np)>corr_thres:\n",
    "                    print(wind, comp, (nlabels[i],b), corr_np)\n",
    "                    f = plt.figure(figsize=(2,2), layout='constrained')\n",
    "                    #gs = matplotlib.gridspec.GridSpec(1,12)\n",
    "                    ax = f.add_subplot() #gs[:1]\n",
    "                    if corr_np>0:\n",
    "                        ax.plot(p, color='k', label=i+1)\n",
    "                    else:\n",
    "                        ax.plot(-p, color='k', label=i+1)\n",
    "                    ninds = np.argsort(best_factors[0].T[i])\n",
    "                    nlab_sorted = [list(nlabels)[nind] for nind in ninds]\n",
    "                    ax1 = ax.twinx()\n",
    "                    ax1.plot(moving_window_average(jsons[w][b][:num_timepoints], window_size, 1), color='gray', label=b)\n",
    "\n",
    "                    # ax1 = f.add_subplot(gs[1:]) \n",
    "                    # ax1.scatter(np.arange(len(nlabels)), best_factors[1].T[i][ninds])\n",
    "                    # ax1.set_xticks(np.arange(len(nlabels)), nlab_sorted, rotation=45, fontsize='x-small')\n",
    "                    #simpleaxis([ax, ax1])\n",
    "                    plt.legend()\n",
    "                    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_avg = []\n",
    "#for wind,w in enumerate(worms):\n",
    "    #best_core, best_factors = core_worms[w], factor_worms[w]\n",
    "vm = np.abs(best_factors[1]).max() \n",
    "f, ax = plt.subplots(figsize=(4,12), layout='constrained')\n",
    "ax.pcolor(best_factors[1], vmin=-vm, vmax=vm, cmap='PuOr')\n",
    "plt.xticks(np.arange(n_rank)+0.5, np.arange(n_rank)+1)\n",
    "plt.yticks(np.arange(len(nlabels))+0.5, nlabels)\n",
    "plt.show()\n",
    "#factor_avg.append(best_factors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_factor = np.mean(factor_avg, axis=0)\n",
    "vm = np.abs(mean_factor).max()\n",
    "f, ax = plt.subplots(figsize=(4,12), layout='constrained')\n",
    "cbar = ax.pcolor(mean_factor, vmin=-vm, vmax=vm, cmap='PuOr')\n",
    "plt.xticks(np.arange(n_rank)+0.5, np.arange(n_rank)+1)\n",
    "plt.yticks(np.arange(len(nlabels))+0.5, nlabels)\n",
    "plt.colorbar(cbar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conns = {}\n",
    "ligands= ('Serotonin', ) #'Dopamine',) #)\n",
    "connFilter = 'chemical-synapse' #'gap-junction'\n",
    "for c,e in nn.connections.items():\n",
    "    if connFilter:\n",
    "        if e.connection_type == connFilter:\n",
    "            #print(e.putative_neurotrasmitter_receptors)\n",
    "            for ligand in ligands:\n",
    "                if ligand in e.ligands:\n",
    "                    for nt_rec in e.putative_neurotrasmitter_receptors:\n",
    "                        if nt_rec[0] in ligands:\n",
    "                            if not nt_rec in conns:\n",
    "                                conns[nt_rec] = []\n",
    "                            conns[nt_rec].append([c[0].name, c[1].name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ser = []\n",
    "for key in conns.keys():\n",
    "    all_ser+=conns[key][0]\n",
    "    all_ser+=conns[key][1]\n",
    "all_ser = set(all_ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_nx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac1_dot = best_factors[1].T[19]\n",
    "conn_arr = np.linspace(np.min(fac1_dot), 0.99*np.max(fac1_dot), 100)\n",
    "edges = []\n",
    "fracCommon = []\n",
    "commonNeurs = []\n",
    "for conn_thres in conn_arr:\n",
    "    mat_nx = np.abs(fac1_dot)>conn_thres\n",
    "    connected_n = [nlabels[j] for j in np.argwhere(mat_nx).T[0]]\n",
    "    commons = set(connected_n).intersection(all_ser)\n",
    "    commonNeurs.append(commons)\n",
    "    fracCommon.append(len(commons)/len(connected_n))\n",
    "fracAll = len(all_ser)/len(mat_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.hist(np.ravel(fac1_dot), bins=50, cumulative=True, density=True, histtype='step')\n",
    "ax.axhline(y=0.8, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_neuron, factors_neuron = best_core, best_factors\n",
    "projected_data_neuron = tl.tenalg.multi_mode_dot(best_core, best_factors, skip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(1.5,1.5))\n",
    "ax.scatter(conn_arr, fracCommon, color='gray', s=8)\n",
    "ax.axhline(y=fracAll, linestyle='--', color='k')\n",
    "simpleaxis(ax)\n",
    "ax.set_ylim((0,1.05))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(projected_data_neuron[:,j,:,0], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_factors[3].T[0].shape, projected_data_neuron[0,0,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ind = 14\n",
    "m = np.convolve(best_factors[3].T[0], projected_data_neuron[0,0,:,0])\n",
    "n = best_factors[3].T[t_ind]\n",
    "plt.plot(n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_factors[3].T.shape, rank_grid['t_rank'], corr_thres, projected_data_neuron[:,j,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_recompose(recon_tensor):\n",
    "    reconstructed_matrix = np.zeros((recon_tensor.shape[0], recon_tensor.shape[1]+recon_tensor.shape[2]-1))\n",
    "    weight_matrix = np.zeros_like(reconstructed_matrix)\n",
    "    for i in range(recon_tensor.shape[1]):\n",
    "        reconstructed_matrix[:, i:i+100] += recon_tensor[:, i, :]\n",
    "        weight_matrix[:, i:i+100] += 1\n",
    "        # Average where overlaps occurred\n",
    "    reconstructed_matrix /= weight_matrix\n",
    "    return reconstructed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,3*rank_grid['n_rank']), nrows=rank_grid['n_rank'], sharex=True, sharey=True, layout='constrained')\n",
    "ax1 = [a.twinx() for a in ax]\n",
    "naive_avg = {}\n",
    "trained_avg = {}\n",
    "t_ind = 2\n",
    "corr_thres = 0.81\n",
    "for j in range(rank_grid['n_rank']):\n",
    "    # naive_avg[r] = []\n",
    "    # trained_avg[r] = []\n",
    "    avg_beh = []\n",
    "    avg_comp_tc = []\n",
    "    reconstruction = moving_average_recompose(projected_data_neuron[:,j,:,:])\n",
    "    for i,(p,w) in enumerate(zip(reconstruction, jsons.keys())):\n",
    "        component_timecourse = p\n",
    "        avg_beh.append(jsons[w]['pumping'][:num_timepoints])\n",
    "        avg_comp_tc.append(component_timecourse)\n",
    "        if np.abs(np.corrcoef(component_timecourse, jsons[w]['pumping'][:num_timepoints])[0,1])>corr_thres:\n",
    "            print(j,i, np.corrcoef(component_timecourse, jsons[w]['pumping'][:num_timepoints])[0,1])\n",
    "            ax[j].plot(component_timecourse, color='gray', alpha=0.5)\n",
    "            ax1[j].plot(jsons[w]['pumping'], color='orange', alpha=0.5)\n",
    "        # ax[j].plot(jsons[w]['pumping'], color='orange', alpha=0.5)\n",
    "    # ax[j].plot(np.mean(avg_comp_tc, axis=0), color='k')\n",
    "    # ax[j].plot(np.mean(avg_beh, axis=0), color='red')\n",
    "    # naive_avg[r] = np.mean(naive_avg[r], axis=0)\n",
    "    # trained_avg[r] = np.mean(trained_avg[r], axis=0)\n",
    "    # ax[j].plot(np.linspace(0,90, len(p)), naive_avg[r], color='k') \n",
    "    # ax[j].plot(np.linspace(0,90, len(p)), trained_avg[r], color='r')\n",
    "    simpleaxis(ax[j])\n",
    "f.supxlabel(\"Time(s)\")\n",
    "f.supylabel(f\"Compomnent projection amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,b in zip(fracCommon, commonNeurs):\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(conn_arr[:-1], np.diff(edges))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_thres = 0.01\n",
    "mat_nx = np.abs(fac1_dot)>conn_thres\n",
    "graph = utils.nx.from_numpy_array(mat_nx)\n",
    "node_labels = {i:n for i,n in enumerate(nlabels)}\n",
    "G = utils.nx.relabel_nodes(graph, node_labels)\n",
    "\n",
    "H = G.edge_subgraph(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(all_ser).intersection(set(H.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(12,12))\n",
    "utils.nx.draw_kamada_kawai(H, with_labels=True, ax=ax, node_size=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.loadNeurotransmitters(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ntr, conn in conns.items():\n",
    "    print(ntr)\n",
    "    pos = utils.plot_layered(conn, nn, nodeColors={}, edgeColors = 'gray', save=False, title=ntr, extraNodes=[], extraEdges=[], pos=[], mark_anatomical=False, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x, y, z = np.nonzero(best_core)\n",
    "c = best_core[x, y, z]  # Color by value\n",
    "alpha = np.where(c > 1e-2, 1.0, 0.0)\n",
    "vm=0.01\n",
    "plt.pcolor(best_core[:,:,9], cmap='PuOr', vmin=-vm, vmax=vm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get the coordinates for non-zero elements\n",
    "x, y, z = np.nonzero(best_core)\n",
    "c = best_core[x, y, z]  # Color by value\n",
    "\n",
    "# Scatter plot\n",
    "sc = ax.scatter(x, y, z, c=c, cmap='viridis', s=100)\n",
    "\n",
    "# Add color bar\n",
    "plt.colorbar(sc, ax=ax)\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "plt.title(\"3D Core Tensor from Tucker Decomposition\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "across_pairs = {}\n",
    "min_pairs = 20\n",
    "min_reps = 10\n",
    "while len(across_pairs)<min_pairs:\n",
    "    i = np.random.randint(len(neuron_labels))\n",
    "    j = np.random.randint(len(neuron_labels)) \n",
    "    n1 = neuron_labels[i]\n",
    "    n2 = neuron_labels[j]\n",
    "    tempvec = []\n",
    "    if n1 == 'RMGL':\n",
    "        for database in jsons.keys():\n",
    "            vecs = [by_database[database][window_size][i,j] for window_size in window_sizes if not np.isnan(by_database[database][window_size][i,j])]\n",
    "            if len(vecs):\n",
    "                tempvec.append(vecs)\n",
    "        \n",
    "        if len(tempvec)>min_reps:\n",
    "            f, ax = plt.subplots()\n",
    "            for t in tempvec:\n",
    "                ax.plot(window_sizes, t, color='gray')\n",
    "            ax.plot(window_sizes, np.median(tempvec, axis=0), color='k')\n",
    "\n",
    "            ax.set_title((n1,n2))\n",
    "            ax.set_ylim((-1,1))\n",
    "            plt.show()\n",
    "            across_pairs[(n1,n2)] = tempvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_window = np.zeros((len(measuredNeurons[database]), len(measuredNeurons[database])))\n",
    "conn_mat = np.zeros((len(measuredNeurons[database]), len(measuredNeurons[database]))) \n",
    "\n",
    "for i,n1 in enumerate(neuron_labels):\n",
    "    for j,n2 in enumerate(neuron_labels):\n",
    "        if n1 in weight_mat:\n",
    "            if n2 in weight_mat[n1]:\n",
    "                weight_window[i,j] = weight_mat[n1][n2]\n",
    "                if (nn.neurons[n1], nn.neurons[n2], 0) in nn.connections.keys():\n",
    "                    conn_mat[i,j] = 1\n",
    "\n",
    "ax0_ind = np.argwhere(conn_mat.ravel()==0)\n",
    "ax1_ind = np.argwhere(conn_mat.ravel()==1)\n",
    "\n",
    "f, ax = plt.subplots(figsize= (4,2*len(by_window.keys())), ncols=2, nrows=len(by_window.keys()), sharex=True, sharey=True)\n",
    "\n",
    "for j, window_size in enumerate(window_sizes):\n",
    "    ax[j,0].scatter(by_window[window_size].ravel()[ax0_ind], weight_window.ravel()[ax0_ind], c='gray')\n",
    "    ax[j,1].scatter(by_window[window_size].ravel()[ax1_ind], weight_window.ravel()[ax1_ind], c='purple')\n",
    "    for a in ax[j]:\n",
    "        a.axhline(y=0, linestyle='--', color='gray')\n",
    "        a.axvline(x=0, linestyle='--', color='gray')\n",
    "        a.set_xlim((-1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeColors = {}\n",
    "nodelist = []\n",
    "for neuron in nn.neurons:\n",
    "    if neuron in measuredNeurons[database]:\n",
    "        nodeColors[neuron] = nn.neurons[neuron].amplitude\n",
    "        nn.neurons[neuron].set_property('color', nn.neurons[neuron].amplitude)\n",
    "        nodelist.append(neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_2 = nn.subnetwork(nodelist, as_view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Giving the sex specific neurons an interneuron type for positioning on graph.\n",
    "sex_neurons = ['CANL', 'CANR']\n",
    "for n in nn_2.neurons:\n",
    "    if n in sex_neurons:\n",
    "        nn_2.neurons[n].type = 'interneuron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeColors = []\n",
    "for e in nn_2.connections:\n",
    "    edgeColors.append(nn_2.connections[e].weight)\n",
    "cmap = plt.get_cmap('PuOr')\n",
    "max_color = max(np.abs(edgeColors))\n",
    "norm = matplotlib.colors.Normalize(vmin=-max_color,vmax=max_color)\n",
    "m = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "edge_color_dict = {e: m.to_rgba(nn_2.connections[e].weight) for e in nn_2.connections}\n",
    "\n",
    "\n",
    "max_color = max(np.abs(list(nodeColors.values())))\n",
    "cmap2 = plt.get_cmap('RdYlGn')\n",
    "norm2 = matplotlib.colors.Normalize(vmin=-max_color,vmax=max_color)\n",
    "o = cm.ScalarMappable(norm=norm2, cmap=cmap2)\n",
    "\n",
    "node_color_dict = {nn_2.neurons[n]: o.to_rgba(nn_2.neurons[n].color) for n in nn_2.neurons}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = [n for n in nn_2.neurons if nn_2.neurons[n].type == 'sensory']\n",
    "utils.plot_shell(nn_2, center=center, figsize=(10,10), edge_color_dict=edge_color_dict, node_color_dict=node_color_dict, save=False)#\"weight-activity.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conns = [(e[0].name, e[1].name) for e in nn_2.connections]\n",
    "edgeColors = [nn_2.connections[e].weight for e in nn_2.connections]\n",
    "\n",
    "utils.plot_layered(conns, nn_2, nodeColors=nodeColors, edgeColors=edgeColors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conns = [(e[0].name, e[1].name) for e in nn_2.connections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_2.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nn_2.neurons:\n",
    "    print(n, nn_2.neurons[n].type, nn_2.neurons[n].category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "TOPDIR = '../../' ## Change this to cedne and write a function to download data from an online server for heavy data.\n",
    "DATADIR = TOPDIR + 'data_sources/'\n",
    "DOWNLOAD_DIR = TOPDIR + 'data_sources/downloads/'\n",
    "\n",
    "prefix_NT = 'Wang_2019/'\n",
    "prefix_CENGEN = 'CENGEN/'\n",
    "prefix_NP = 'Ripoll-Sanchez_2023/'\n",
    "prefix_synaptic_weights = 'Randi_2023/'\n",
    "weightMatrix = DOWNLOAD_DIR + prefix_synaptic_weights + \"41586_2023_6683_MOESM13_ESM.xls\"\n",
    "tMat = pd.read_excel(weightMatrix, index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in nn.neurons['AWCL'].out_connections:\n",
    "    if(nn.neurons['AWCR'] in e):\n",
    "        print(nn.connections[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nn_2.neurons: \n",
    "    print(nn_2.neurons[n].type)\n",
    "    print(nn_2.neurons[n].category)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
