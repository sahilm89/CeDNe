{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedne import simulator\n",
    "from cedne import optimizer\n",
    "from cedne import utils\n",
    "from cedne import cedne\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(utils.OUTPUT_DIR):\n",
    "    os.makedirs(utils.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntype = ['sensory', 'interneuron', 'motorneuron']\n",
    "facecolors = ['#FF6F61', '#FFD700', '#4682B4']\n",
    "ntype_pairs = set([tuple(sorted([nt1, nt2])) for nt1 in ntype for nt2 in ntype])\n",
    "colors= plt.cm.magma(np.linspace(0,1,len(ntype_pairs)))\n",
    "type_color_dict = {p:color for (p,color) in zip(ntype_pairs, colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = utils.makeWorm(chem_only=True)\n",
    "nn_chem = w.networks[\"Neutral\"]\n",
    "\n",
    "# w_both = utils.makeWorm()\n",
    "# nn_both = w_both.networks[\"Neutral\"] \n",
    "\n",
    "# w_gapjn = utils.makeWorm(gapjn_only=True)\n",
    "# nn_gapjn = w.networks[\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triad_motifs = utils.return_triads()\n",
    "motif = triad_motifs['030T']\n",
    "motif = utils.nx.relabel_nodes(motif, {1:1, 2:3, 3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hseq = utils.make_hypermotifs(motif, 3, [(3,1)])\n",
    "hseq = utils.nx.relabel_nodes(hseq, {'1.3-2.1':'2.1', '2.3-3.1':'3.1'})\n",
    "hseq = utils.nx.convert_node_labels_to_integers(hseq, first_label=1, ordering='sorted', label_attribute='nodename')\n",
    "all_ffgs = nn_chem.search_motifs(hseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mot_edgelabels = {node:[] for node in hseq}\n",
    "# for ffg in all_ffgs:\n",
    "#     nodelist = {node:None for node in hseq}\n",
    "#     for med, ned in ffg.items():\n",
    "#         for m,n in zip(med, ned):\n",
    "#             nodelist[m] = n.name\n",
    "#     for node in nodelist:\n",
    "#         mot_edgelabels[node].append(nodelist[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_interneurons = ['AVAL', 'AVAR', 'AVBL', 'AVBR', 'AVDL', 'AVDR', 'AVEL', 'AVER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = []\n",
    "input_neurons = []\n",
    "\n",
    "mot_edgelabels = {node:[] for node in hseq}\n",
    "neuron_layers = {node:[] for node in hseq}\n",
    "for ffg in all_ffgs:\n",
    "    nodelist = {node:None for node in hseq}\n",
    "    for med, ned in ffg.items():\n",
    "        for m,n in zip(med, ned):\n",
    "            nodelist[m] = n.name\n",
    "    if nodelist[5] in command_interneurons:\n",
    "        edgelist+= [(e[0], e[1], 0) for e in ffg.values() if not (e[0], e[1], 0) in edgelist]\n",
    "        input_neurons.append(nodelist[1])\n",
    "        for m in nodelist:\n",
    "            neuron_layers[m].append(nodelist[m])\n",
    "input_neurons = list(sorted(set(input_neurons)))\n",
    "neuron_layers = {layer: list(set(neuron_layers[layer])) for layer in neuron_layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_chem_sub = nn_chem.subnetwork(connections=edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = {}\n",
    "for js in os.listdir('/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/'):\n",
    "    with open (\"/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/{}\".format(js), 'r') as f:\n",
    "        jsons['Atanas et al (2023) ' +  js] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measuredNeurons = {}\n",
    "neuron_labels = []\n",
    "for js, p in jsons.items():\n",
    "    sortedKeys = sorted ([int(x) for x in (p['labeled'].keys())])\n",
    "    labelledNeurons = {p['labeled'][str(x)]['label']:x for x in sortedKeys if not '?' in p['labeled'][str(x)]['label']} # Removing unsure hits\n",
    "    measuredNeurons[js] = {m:i for i,m in enumerate(set(labelledNeurons))}\n",
    "    neuron_labels+=measuredNeurons[js].keys()\n",
    "neuron_labels = sorted(set(neuron_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "best_models = {}\n",
    "for database in jsons.keys():\n",
    "    ## Subnetwork and optimize\n",
    "    nn_chem_sub = nn_chem.subnetwork(connections=edgelist)\n",
    "\n",
    "    ## Parameter Setup\n",
    "    inputs = []\n",
    "    tconstants = [1] *len(nn_chem_sub.nodes)\n",
    "    input_nodes = [nn_chem_sub.neurons[n] for n in input_neurons]\n",
    "\n",
    "    weights = {e:1 for e in nn_chem_sub.edges}\n",
    "    gains = {node:1.0 for node in nn_chem_sub.nodes}\n",
    "    baselines = {node:0. for node in nn_chem_sub.nodes}\n",
    "    time_constants = {n:t for n,t in zip(nn_chem_sub.nodes, tconstants)}\n",
    "    num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][list(measuredNeurons[database].keys())[0]]])\n",
    "    for neuron in nn_chem_sub.neurons:\n",
    "        if neuron in measuredNeurons[database]:\n",
    "            nn_chem_sub.neurons[neuron].set_property('amplitude', jsons[database]['trace_array'][measuredNeurons[database][neuron]][:num_timepoints])\n",
    "    time_points = np.arange(num_timepoints)#jsons[database]['max_t'])\n",
    "\n",
    "    ## Inputs\n",
    "    for inp in input_nodes:\n",
    "        if hasattr(inp, 'amplitude'):\n",
    "            input_value = {t:inp.amplitude[t] for t in time_points}\n",
    "            inputs.append(simulator.TimeSeriesInput([inp], input_value))\n",
    "\n",
    "    ## Initialize rate model\n",
    "    rate_model = simulator.RateModel(nn_chem_sub, input_nodes, weights, gains, time_constants, baselines, static_nodes=input_nodes, \\\n",
    "                                        time_points=time_points, inputs=inputs)\n",
    "    \n",
    "    node_parameter_bounds =  {'gain': {rn:(-1, 1) for n,rn in rate_model.node_dict.items() if not n in input_nodes}, \\\n",
    "                                'time_constant': {rn:(1, 5) for n,rn in rate_model.node_dict.items() if not n in input_nodes},\n",
    "                                'baseline': {rn:(-2, 2) for n,rn in rate_model.node_dict.items() if not n in input_nodes}}\n",
    "    edge_parameter_bounds = {'weight': {e:(-2, 2) for e in rate_model.edges}}\n",
    "    \n",
    "    real = {rate_model.node_dict[node]:data['amplitude'] for node,data in nn_chem_sub.nodes(data=True) if 'amplitude' in data}\n",
    "    vars_to_fit = [rn for rn in real.keys() if not rn in [rate_model.node_dict[n] for n in input_nodes]]\n",
    "    \n",
    "    ## Setting parameter bounds for the paramters of interest and set the rest to default to simulate. Use a noisy output to fit.\n",
    "    o = optimizer.OptunaOptimizer(rate_model, real, optimizer.mean_squared_error, node_parameter_bounds, edge_parameter_bounds, vars_to_fit, num_trials=num_trials)\n",
    "    best_params, best_model = o.optimize()\n",
    "    best_fit = best_model.simulate()\n",
    "\n",
    "    best_models[database] = (best_params, best_model)\n",
    "    \n",
    "    plot_rows = [k for k in best_fit.keys() if not str(k.label) in input_neurons and hasattr(nn_chem_sub.neurons[str(k.label)], 'amplitude')]\n",
    "    f, ax = plt.subplots(figsize=(10,2*len(plot_rows)), nrows=len(plot_rows), sharex=True, layout='constrained')\n",
    "    # for k, (n, node) in enumerate(nodelist):\n",
    "    for j,k in enumerate(plot_rows):\n",
    "        ax[j].plot(nn_chem_sub.neurons[str(k.label)].amplitude, label=f'{k.label}-{nn_chem_sub.neurons[str(k.label)].name}', color='gray')\n",
    "        ax1 = ax[j]\n",
    "        ax1.plot(best_fit[k], color='orange')\n",
    "        utils.simpleaxis(ax[j])\n",
    "        ax[j].set_title(f'{np.corrcoef(nn_chem_sub.neurons[str(k.label)].amplitude, best_fit[k])[0,1]}')\n",
    "        ax[j].legend(frameon=False)\n",
    "    f.suptitle(f'{database}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict = {}\n",
    "for database, (pars, mod) in best_models.items():\n",
    "    for key, val in pars.items():\n",
    "        par, *rest = key.split(':')\n",
    "        if par not in var_dict:\n",
    "            var_dict[par] = {}\n",
    "        if not tuple(rest) in var_dict[par]:\n",
    "            var_dict[par][tuple(rest)] = []\n",
    "        var_dict[par][tuple(rest)].append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(24,8), nrows= len(var_dict)-1, layout='constrained', sharex=True)\n",
    "for j, (par, vars) in enumerate(sorted(var_dict.items(), key=lambda x:x[0])):\n",
    "    xticks = []\n",
    "    if not par == 'weight':\n",
    "        for k, (n, val) in enumerate(vars.items()):\n",
    "            ax[j].scatter([k]*len(val), val)\n",
    "            xticks.append('-'.join(n))\n",
    "        ax[j].set_xticks(np.arange(len(xticks)), xticks, rotation=45)\n",
    "        utils.simpleaxis(ax[j])\n",
    "        ax[j].set_title(par)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20,12), layout='constrained', nrows=len(var_dict['weight'])//100+1)\n",
    "xticks=[]\n",
    "for j, (n, val) in enumerate(var_dict['weight'].items()):\n",
    "    ax[j//100].scatter([j%100]*len(val), val)\n",
    "    xticks.append('-'.join(n))\n",
    "    # ax[j//100].set_xticks(np.arange(len(xticks)), xticks, rotation=45)\n",
    "utils.simpleaxis(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(36,8), layout='constrained', nrows=2)\n",
    "xticks_1=[]\n",
    "xticks_2=[]\n",
    "k1=0\n",
    "k2 = 0\n",
    "for j, (n, val) in enumerate(var_dict['weight'].items()):\n",
    "    if n[1] in command_interneurons:\n",
    "        ax[0].scatter([k1]*len(val), val)\n",
    "        xticks_1.append('-'.join(n))\n",
    "        k1+=1\n",
    "    if n[0] in command_interneurons:\n",
    "        ax[1].scatter([k2]*len(val), val)\n",
    "        xticks_2.append('-'.join(n))\n",
    "        k2+=1\n",
    "ax[0].set_xticks(np.arange(len(xticks_1)), xticks_1, rotation=45, fontsize='x-large')\n",
    "ax[1].set_xticks(np.arange(len(xticks_2)), xticks_2, rotation=45, fontsize='x-large')\n",
    "utils.simpleaxis(ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_motif = ['1.1', '1.2', '2.1', '2.2', '3.1']\n",
    "tconstants = [1, 1, 1, 1,1,1,1]\n",
    "input_nodes = [min_motif[0]]\n",
    "\n",
    "weights = {e:1 for e in hseq.edges}\n",
    "gains = {node:1.0 for node in hseq.nodes}\n",
    "baselines = {node:0. for node in hseq.nodes}\n",
    "time_constants = {n:t for n,t in zip(hseq.nodes, tconstants)}\n",
    "\n",
    "# countdown = 10\n",
    "for database in jsons.keys():\n",
    "    nn_chem_sub = nn_chem.subnetwork(connections=all_edges)\n",
    "    all_ffgs = nn_chem_sub.search_motifs(hseq)\n",
    "    num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][list(measuredNeurons[database].keys())[0]]])\n",
    "    for neuron in nn_chem_sub.neurons:\n",
    "        if neuron in measuredNeurons[database]:\n",
    "            nn_chem_sub.neurons[neuron].set_property('amplitude', jsons[database]['trace_array'][measuredNeurons[database][neuron]])\n",
    "    \n",
    "    by_motif = {}\n",
    "    for j,ffg in enumerate(all_ffgs):\n",
    "        nodelist = []\n",
    "        for edge in sorted(edges):\n",
    "            if hasattr(nn_chem_sub.neurons[ffg[edge][0].name], 'amplitude') and hasattr(nn_chem_sub.neurons[ffg[edge][1].name], 'amplitude'):\n",
    "                nodelist+= [(edge[0], ffg[edge][0].name), (edge[1], ffg[edge][1].name)]\n",
    "        nodelist = sorted(set(nodelist))\n",
    "        if nodelist:# and countdown>0:\n",
    "            if all(n in list(zip(*nodelist))[0] for n in min_motif):\n",
    "                \n",
    "                cedne.GraphMap(ffg, hseq, nn_chem_sub, map_type='edge')\n",
    "                inputs = []\n",
    "                time_points = np.arange(0,jsons[database]['max_t'])\n",
    "                for inp in input_nodes:\n",
    "                    if hasattr(nn_chem_sub.neurons[hseq.nodes[inp]['map'].name], 'amplitude'):\n",
    "                        input_value = {t:nn_chem_sub.neurons[hseq.nodes[inp]['map'].name].amplitude[t] for t in time_points}\n",
    "                        inputs.append(simulator.TimeSeriesInput(input_nodes, input_value))\n",
    "                rate_model = simulator.RateModel(hseq, input_nodes, weights, gains, time_constants, baselines, static_nodes=input_nodes, time_points=time_points, inputs=inputs)\n",
    "                \n",
    "                node_parameter_bounds =  {'gain': {rn:(0, 5) for n,rn in rate_model.node_dict.items() if not n in input_nodes}, 'time_constant': {rn:(0, 20) for n,rn in rate_model.node_dict.items() if not n in input_nodes}, 'baseline': {rn:(0, 3) for n,rn in rate_model.node_dict.items() if not n in input_nodes}}\n",
    "                edge_parameter_bounds = {'weight': {e:(-10, 10) for e in rate_model.edges}}\n",
    "                \n",
    "                real = {rate_model.node_dict[node]:data['map'].amplitude for node,data in hseq.nodes(data=True) if hasattr(data['map'], 'amplitude')}\n",
    "                vars_to_fit = [rn for rn in real.keys() if not rn in input_nodes]\n",
    "                \n",
    "                ## Setting parameter bounds for the paramters of interest and set the rest to default to simulate. Use a noisy output to fit.\n",
    "                o = optimizer.OptunaOptimizer(rate_model, real, optimizer.mean_squared_error, node_parameter_bounds, edge_parameter_bounds, vars_to_fit, num_trials=1e3)\n",
    "                best_params, best_model = o.optimize()\n",
    "                best_fit = best_model.simulate()\n",
    "                \n",
    "                f, ax = plt.subplots(figsize=(10,2*len(hseq.nodes)), nrows=len(hseq.nodes), sharex=True)\n",
    "                # for k, (n, node) in enumerate(nodelist):\n",
    "                for j,k in enumerate(best_fit.keys()):\n",
    "                    if k.label in list(zip(*nodelist))[0]:\n",
    "                        ax[j].plot(nn_chem_sub.neurons[hseq.nodes[k.label]['map'].name].amplitude, label=f'{k.label}-{hseq.nodes[k.label]['map'].name}', color='gray')\n",
    "                        ax1 = ax[j]\n",
    "                        ax1.plot(best_fit[k], color='orange')\n",
    "                        utils.simpleaxis(ax[j])\n",
    "                        ax[j].set_title(f'{np.corrcoef(nn_chem_sub.neurons[hseq.nodes[k.label]['map'].name].amplitude, best_fit[k])[0,1]}')\n",
    "                        ax[j].legend(frameon=False)\n",
    "                f.suptitle(f'{database}')\n",
    "                plt.show()\n",
    "                # countdown-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triads = utils.return_triads()\n",
    "G = triads['030T']\n",
    "weights = {(1, 3): -3., (3, 2): -1, (1, 2): -3}\n",
    "\n",
    "input_nodes = [1]\n",
    "gains = {node:1.0 for node in G.nodes}\n",
    "tconstants = [10, 10, 1]\n",
    "time_constants = {n:t for n,t in zip(G.nodes, tconstants)}\n",
    "rate_model = simulator.RateModel(G, input_nodes, weights, gains, time_constants, static_nodes=input_nodes)\n",
    "\n",
    "initial_rates = [0., 0., 0.]\n",
    "max_t = 90\n",
    "time_points = np.linspace(0, max_t, 451)\n",
    "\n",
    "inp1_value = 1\n",
    "input_value = {t:inp1_value*np.sin((t/max_t)*2*np.pi) for t in time_points}\n",
    "inp_vals = [input_value[t] for t in time_points]\n",
    "input1= simulator.TimeSeriesInput(input_nodes, input_value)\n",
    "\n",
    "inputs = [input1]\n",
    "\n",
    "rates = rate_model.simulate(time_points, inputs)\n",
    "\n",
    "f = utils.plot_simulation_results((rate_model, inputs, rates), twinx=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
