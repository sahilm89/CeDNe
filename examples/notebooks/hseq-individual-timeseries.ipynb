{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedne import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from cedne import utils\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "from tensorly.decomposition import tucker\n",
    "from tensorly.decomposition import partial_tucker\n",
    "from tensorly.tenalg import multi_mode_dot\n",
    "from tensorly import kruskal_to_tensor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(utils.OUTPUT_DIR):\n",
    "    os.makedirs(utils.OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntype = ['sensory', 'interneuron', 'motorneuron']\n",
    "facecolors = ['#FF6F61', '#FFD700', '#4682B4']\n",
    "ntype_pairs = set([tuple(sorted([nt1, nt2])) for nt1 in ntype for nt2 in ntype])\n",
    "colors= plt.cm.magma(np.linspace(0,1,len(ntype_pairs)))\n",
    "type_color_dict = {p:color for (p,color) in zip(ntype_pairs, colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = utils.makeWorm(chem_only=True)\n",
    "nn_chem = w.networks[\"Neutral\"]\n",
    "\n",
    "w_both = utils.makeWorm()\n",
    "nn_both = w_both.networks[\"Neutral\"] \n",
    "\n",
    "w_gapjn = utils.makeWorm(gapjn_only=True)\n",
    "nn_gapjn = w.networks[\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triad_motifs = utils.return_triads()\n",
    "motif = triad_motifs['030T']\n",
    "motif = utils.nx.relabel_nodes(motif, {1:1, 2:3, 3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = utils.make_hypermotifs(motif, 3, [(3,1)])\n",
    "hm = utils.nx.relabel_nodes(hm, {'1.3-2.1':'2.1', '2.3-3.1':'3.1'})\n",
    "all_ffgs = nn_both.search_motifs(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = sorted(hm.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if gap junctions are somehow different for different nodes of the sequential hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gapjn_by_node = {n:[] for n in hm.nodes}\n",
    "for j,ffg in enumerate(all_ffgs):\n",
    "    for edge in edges:\n",
    "        gapjn_by_node[edge[0]]+= [e[1].name for e in nn_gapjn.neurons[ffg[edge][0].name].get_connections(direction='out')]\n",
    "        gapjn_by_node[edge[1]]+= [e[1].name for e in nn_gapjn.neurons[ffg[edge][1].name].get_connections(direction='out')]\n",
    "for key in gapjn_by_node:\n",
    "    gapjn_by_node[key] = set(gapjn_by_node[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_type = {n:{nt:0 for nt in ntype} for n in hm.nodes}\n",
    "for key in sorted(gapjn_by_node.keys()):\n",
    "    for n in gapjn_by_node[key]:\n",
    "        by_type[key][nn_gapjn.neurons[n].type]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding time series information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = []\n",
    "for ffg in all_ffgs:\n",
    "    for edge in ffg:\n",
    "        all_edges.append((ffg[edge][0], ffg[edge][1], 0))\n",
    "all_edges = list(set(all_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_chem_sub = nn_chem.subnetwork(connections=all_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = utils.make_hypermotifs(motif, 3, [(3,1)])\n",
    "hm = utils.nx.relabel_nodes(hm, {'1.3-2.1':'2.1', '2.3-3.1':'3.1'})\n",
    "all_ffgs = nn_chem_sub.search_motifs(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = {}\n",
    "for js in os.listdir('/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/'):\n",
    "    with open (\"/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/{}\".format(js), 'r') as f:\n",
    "        jsons['Atanas et al (2023) ' +  js] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measuredNeurons = {}\n",
    "neuron_labels = []\n",
    "for js, p in jsons.items():\n",
    "    sortedKeys = sorted ([int(x) for x in (p['labeled'].keys())])\n",
    "    labelledNeurons = {p['labeled'][str(x)]['label']:x for x in sortedKeys if not '?' in p['labeled'][str(x)]['label']} # Removing unsure hits\n",
    "    measuredNeurons[js] = {m:i for i,m in enumerate(set(labelledNeurons))}\n",
    "    neuron_labels+=measuredNeurons[js].keys()\n",
    "neuron_labels = sorted(set(neuron_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for database in jsons.keys():\n",
    "    ## Subnetwork and optimize\n",
    "    nn_chem_sub = nn_chem.subnetwork(connections=all_edges)\n",
    "    hm = utils.make_hypermotifs(motif, 3, [(3,1)])\n",
    "    hm = utils.nx.relabel_nodes(hm, {'1.3-2.1':'2.1', '2.3-3.1':'3.1'})\n",
    "    all_ffgs = nn_chem_sub.search_motifs(hm)\n",
    "    ## Parameter Setup\n",
    "    inputs = []\n",
    "    tconstants = [1] *len(nn_chem_sub.nodes)\n",
    "    input_nodes = [nn_chem_sub.neurons[n] for n in input_neurons]\n",
    "\n",
    "    weights = {e:1 for e in nn_chem_sub.edges}\n",
    "    gains = {node:1.0 for node in nn_chem_sub.nodes}\n",
    "    baselines = {node:0. for node in nn_chem_sub.nodes}\n",
    "    time_constants = {n:t for n,t in zip(nn_chem_sub.nodes, tconstants)}\n",
    "    num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][list(measuredNeurons[database].keys())[0]]])\n",
    "    for neuron in nn_chem_sub.neurons:\n",
    "        if neuron in measuredNeurons[database]:\n",
    "            nn_chem_sub.neurons[neuron].set_property('amplitude', jsons[database]['trace_array'][measuredNeurons[database][neuron]][:num_timepoints])\n",
    "    time_points = np.arange(num_timepoints)#jsons[database]['max_t'])\n",
    "\n",
    "    ## Inputs\n",
    "    for inp in input_nodes:\n",
    "        if hasattr(inp, 'amplitude'):\n",
    "            input_value = {t:inp.amplitude[t] for t in time_points}\n",
    "            inputs.append(simulator.TimeSeriesInput([inp], input_value))\n",
    "\n",
    "    ## Initialize rate model\n",
    "    rate_model = simulator.RateModel(nn_chem_sub, input_nodes, weights, gains, time_constants, baselines, static_nodes=input_nodes, \\\n",
    "                                        time_points=time_points, inputs=inputs)\n",
    "    \n",
    "    node_parameter_bounds =  {'gain': {rn:(-1, 1) for n,rn in rate_model.node_dict.items() if not n in input_nodes}, \\\n",
    "                                'time_constant': {rn:(1, 5) for n,rn in rate_model.node_dict.items() if not n in input_nodes},\n",
    "                                'baseline': {rn:(-2, 2) for n,rn in rate_model.node_dict.items() if not n in input_nodes}}\n",
    "    edge_parameter_bounds = {'weight': {e:(-2, 2) for e in rate_model.edges}}\n",
    "    \n",
    "    real = {rate_model.node_dict[node]:data['amplitude'] for node,data in nn_chem_sub.nodes(data=True) if 'amplitude' in data}\n",
    "    vars_to_fit = [rn for rn in real.keys() if not rn in [rate_model.node_dict[n] for n in input_nodes]]\n",
    "    \n",
    "    ## Setting parameter bounds for the paramters of interest and set the rest to default to simulate. Use a noisy output to fit.\n",
    "    o = optimizer.OptunaOptimizer(rate_model, real, optimizer.mean_squared_error, node_parameter_bounds, edge_parameter_bounds, vars_to_fit, num_trials=num_trials)\n",
    "    best_params, best_model = o.optimize()\n",
    "    best_fit = best_model.simulate()\n",
    "\n",
    "    best_models[database] = (best_params, best_model)\n",
    "    \n",
    "    plot_rows = [k for k in best_fit.keys() if not str(k.label) in input_neurons and hasattr(nn_chem_sub.neurons[str(k.label)], 'amplitude')]\n",
    "    f, ax = plt.subplots(figsize=(10,2*len(plot_rows)), nrows=len(plot_rows), sharex=True, layout='constrained')\n",
    "    # for k, (n, node) in enumerate(nodelist):\n",
    "    for j,k in enumerate(plot_rows):\n",
    "        ax[j].plot(nn_chem_sub.neurons[str(k.label)].amplitude, label=f'{k.label}-{nn_chem_sub.neurons[str(k.label)].name}', color='gray')\n",
    "        ax1 = ax[j]\n",
    "        ax1.plot(best_fit[k], color='orange')\n",
    "        utils.simpleaxis(ax[j])\n",
    "        ax[j].set_title(f'{np.corrcoef(nn_chem_sub.neurons[str(k.label)].amplitude, best_fit[k])[0,1]}')\n",
    "        ax[j].legend(frameon=False)\n",
    "    f.suptitle(f'{database}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parameter_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(best_params, rate_model, node_params, edge_params):\n",
    "    node_params_new = copy.deepcopy(node_params)\n",
    "    edge_params_new = copy.deepcopy(edge_params)\n",
    "    print(node_params_new, node_params)\n",
    "    for key in best_params:\n",
    "        split_key = key.split(':')\n",
    "        if len(split_key)==2:\n",
    "            node_params_new[split_key[0]][rate_model.node_dict[split_key[1]]] *=best_params[key]\n",
    "        elif len(split_key)==4:\n",
    "            edge_params_new[split_key[0]][rate_model.node_dict[split_key[1], rate_model.node_dict[split_key[2]]]] *= best_params[key]\n",
    "    return node_params_new, edge_params_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_params(best_params=best_params, rate_model=rate_model, node_params=node_parameter_bounds, edge_params=edge_parameter_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cedne import simulator\n",
    "from cedne import optimizer\n",
    "from cedne import GraphMap\n",
    "num_trials = 100\n",
    "best_models = {}\n",
    "input_nodes = ['1.1']\n",
    "min_motif = ['1.1', '1.2', '2.1']\n",
    "num_trials = 50\n",
    "best_models = {}\n",
    "\n",
    "\n",
    "for database in jsons.keys():\n",
    "    nn_chem_sub = nn_chem.subnetwork(connections=all_edges)\n",
    "    hm = utils.make_hypermotifs(motif, 3, [(3,1)])\n",
    "    hm = utils.nx.relabel_nodes(hm, {'1.3-2.1':'2.1', '2.3-3.1':'3.1'})\n",
    "    all_ffgs = nn_chem_sub.search_motifs(hm)\n",
    "    num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][list(measuredNeurons[database].keys())[0]]])\n",
    "    for neuron in nn_chem_sub.neurons:\n",
    "        if neuron in measuredNeurons[database]:\n",
    "            nn_chem_sub.neurons[neuron].set_property('amplitude', jsons[database]['trace_array'][measuredNeurons[database][neuron]])\n",
    "    \n",
    "    time_points = np.arange(num_timepoints)#jsons[database]['max_t'])\n",
    "    ## Inputs\n",
    "    for inp in input_nodes:\n",
    "        if hasattr(inp, 'amplitude'):\n",
    "            input_value = {t:inp.amplitude[t] for t in time_points}\n",
    "            inputs.append(simulator.TimeSeriesInput([inp], input_value))\n",
    "\n",
    "    by_motif = {}\n",
    "    for j,ffg in enumerate(all_ffgs):\n",
    "        GraphMap(ffg, hm, nn_chem_sub, map_type='edge')\n",
    "        ## Initialize rate model\n",
    "        weights = {e:1 for e in hm.edges}\n",
    "        gains = {node:1.0 for node in hm.nodes}\n",
    "        baselines = {node:0. for node in hm.nodes}\n",
    "        time_constants = {n:t for n,t in zip(hm.nodes, tconstants)}\n",
    "        num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][list(measuredNeurons[database].keys())[0]]])\n",
    "\n",
    "        rate_model = simulator.RateModel(hm, input_nodes, weights, gains, time_constants, baselines, static_nodes=input_nodes, \\\n",
    "                                            time_points=time_points, inputs=inputs)\n",
    "        \n",
    "        node_parameter_bounds =  {'gain': {rn:(1, 1) for n,rn in rate_model.node_dict.items() if not n in input_nodes}, \\\n",
    "                                    'time_constant': {rn:(1, 5) for n,rn in rate_model.node_dict.items() if not n in input_nodes},\n",
    "                                    'baseline': {rn:(0, 1) for n,rn in rate_model.node_dict.items() if not n in input_nodes}}\n",
    "        edge_parameter_bounds = {'weight': {e:(-1, 1) for e in rate_model.edges}}\n",
    "        \n",
    "        \n",
    "        real = {rate_model.node_dict[node]:data['map'].amplitude for node,data in hm.nodes(data=True) if hasattr(data['map'],'amplitude')}\n",
    "        \n",
    "        \n",
    "        ## Setting parameter bounds for the paramters of interest and set the rest to default to simulate. Use a noisy output to fit.\n",
    "\n",
    "        for m in range(len(hm.nodes)):\n",
    "            vars_to_fit = [rn for rn in real.keys() if rn in [rate_model.node_dict[n] for n in sorted(rate_model.node_dict.keys())[1:m]]]\n",
    "            o = optimizer.OptunaOptimizer(rate_model, real, optimizer.mean_squared_error, node_parameter_bounds, edge_parameter_bounds, vars_to_fit, num_trials=num_trials)\n",
    "            best_params, best_model = o.optimize()\n",
    "\n",
    "            node_parameter_bounds = {'gain': {rn:(1, 1) for n,rn in rate_model.node_dict.items() if not n in input_nodes}, \\\n",
    "                                    'time_constant': {rn:(1, 5) for n,rn in rate_model.node_dict.items() if not n in input_nodes},\n",
    "                                    'baseline': {rn:(0, 1) for n,rn in rate_model.node_dict.items() if not n in input_nodes}} \n",
    "\n",
    "        best_fit = best_model.simulate()\n",
    "\n",
    "        best_models[database] = (best_params, best_model)\n",
    "        \n",
    "        nodelist = []\n",
    "        for edge in sorted(edges):\n",
    "            if hasattr(nn_chem_sub.neurons[ffg[edge][0].name], 'amplitude') and hasattr(nn_chem_sub.neurons[ffg[edge][1].name], 'amplitude'):\n",
    "                nodelist+= [(edge[0], ffg[edge][0].name), (edge[1], ffg[edge][1].name)]\n",
    "        nodelist = sorted(set(nodelist))\n",
    "        if len(nodelist)>=len(min_motif):\n",
    "            if all(item in list(zip(*nodelist))[0] for item in min_motif):\n",
    "                if nn_chem_sub.neurons[nodelist[0][1]].type == 'sensory':\n",
    "                    f, ax = plt.subplots(figsize=(10,2*len(hm.nodes)), nrows=len(hm.nodes), sharex=True, sharey=True)\n",
    "                    for k, (edge, node) in enumerate(nodelist):\n",
    "                        ax[k].plot(nn_chem_sub.neurons[node].amplitude[1000:2500], label=f'{edge}: {node}', color='gray')\n",
    "                        ax[k].plot(best_fit[node], color='orange')\n",
    "                        ax[k].legend(frameon=False)\n",
    "                    utils.simpleaxis(ax)\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(nn_chem_sub.neurons[nodelist[0][1]].type, nn_chem_sub.neurons[nodelist[-1][1]].type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, data in hm.nodes(data=True):\n",
    "    print(node, data['map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffg[('1.1', '1.2')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
