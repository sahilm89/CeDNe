{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cedne\n",
    "from cedne import utils\n",
    "from cedne import simulator\n",
    "import numpy as np\n",
    "import json\n",
    "import scipy.stats as ss\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = '/Users/sahilmoza/Documents/Codes/CEDNe/examples/python/cluster_plots/5406695'\n",
    "storage = \"postgresql://smoza@/cedne_optimization_optuna?host=/tmp&port=5433\"\n",
    "frozen_studies = optuna.storages.RDBStorage(storage).get_all_studies()\n",
    "for frozen_study in frozen_studies:\n",
    "    study = optuna.load_study(study_name=frozen_study.study_name, storage=storage)\n",
    "    trials = study.trials\n",
    "    trial_numbers = [t.number for t in trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    loss_values = [t.value for t in trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "    # Plot loss over trials\n",
    "    f, ax = plt.subplots(figsize=(5,3))\n",
    "    ax.plot(trial_numbers, loss_values, marker=\"o\", linestyle=\"-\", color=\"gray\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Trial Number\")\n",
    "    ax.set_ylabel(\"Log Loss\")\n",
    "    # ax.set_title(f\"{study_name} Loss over Trials\")\n",
    "    utils.simpleaxis(ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_study.study_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = {}\n",
    "for js in os.listdir('/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/'):\n",
    "    with open (\"/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/{}\".format(js), 'r') as f:\n",
    "        jsons['/n/home05/smoza/CEDNe/data_sources/downloads/Atanas_2023/Control/' + js+'_50_25_64'] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {study.study_name: study.best_params}\n",
    "neurons = {}\n",
    "for study_name in best_params.keys():\n",
    "    nrs = []\n",
    "    params = best_params[study_name]\n",
    "    for key in params.keys():\n",
    "        if key.startswith('weight'):\n",
    "            _, n1, n2, _ = key.split(':')\n",
    "            nrs.append(n1)\n",
    "            nrs.append(n2)\n",
    "            nrs = list(set(nrs))\n",
    "    neurons[study_name] = nrs\n",
    "\n",
    "database = study.study_name\n",
    "nn_chem_sub = nn_chem.subnetwork(neuron_names=neurons[database])\n",
    "for neuron in nn_chem_sub.neurons:\n",
    "    if neuron in neurons[database]:\n",
    "        nn_chem_sub.neurons[neuron].set_property('amplitude', jsons[database]['trace_array'][measuredNeurons[database][neuron]])\n",
    "\n",
    "num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][list(measuredNeurons[database].keys())[0]]])\n",
    "input_nodes = [nn_chem_sub.neurons[n] for n in nn_chem_sub.neurons if nn_chem_sub.neurons[n].type == 'sensory']\n",
    "inputs = []\n",
    "time_points = np.arange(num_timepoints)\n",
    "for inp in input_nodes:\n",
    "    if hasattr(inp, 'amplitude'):\n",
    "        input_value = {t:inp.amplitude[j] for j,t in enumerate(time_points)}\n",
    "        inputs.append(simulator.TimeSeriesInput([inp], input_value))\n",
    "\n",
    "params = parse_parameters(best_params[database])\n",
    "\n",
    "baseline = {nn_chem_sub.neurons[n]:0 for n in nn_chem_sub.neurons}\n",
    "gains = {nn_chem_sub.neurons[n]:1 for n in nn_chem_sub.neurons}\n",
    "time_constants = {nn_chem_sub.neurons[n]:1 for n in nn_chem_sub.neurons}\n",
    "weights = {(nn_chem_sub.neurons[e[0].name], nn_chem_sub.neurons[e[1].name]):1 for e in nn_chem_sub.edges}\n",
    "\n",
    "baseline.update({nn_chem_sub.neurons[n]:v for n,v in params['baseline'].items()})\n",
    "gains.update({nn_chem_sub.neurons[n]:v for n,v in params['gain'].items()})\n",
    "time_constants.update({nn_chem_sub.neurons[n]:v for n,v in params['time_constant'].items()})\n",
    "weights.update({(nn_chem_sub.neurons[e[0]],nn_chem_sub.neurons[e[1]]):v for e,v in params['weight'].items()})\n",
    "\n",
    "rate_model = simulator.RateModel(nn_chem_sub, input_nodes, weights, gains, time_constants, baseline, static_neurons=input_nodes, \\\n",
    "                                        time_points=time_points, inputs=inputs)\n",
    "rate_model.time_points = time_points\n",
    "res = rate_model.simulate()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,2*len(res.keys())), nrows=len(res.keys()), sharex=True, layout='constrained')\n",
    "# for k, (n, node) in enumerate(nodelist):\n",
    "for j,k in enumerate(res.keys()):\n",
    "    utils.simpleaxis(ax[j])\n",
    "    if hasattr(nn_chem_sub.neurons[str(k.name)], 'amplitude'):\n",
    "        ax[j].plot(np.arange(num_timepoints), np.array(nn_chem_sub.neurons[str(k.name)].amplitude), color='gray')\n",
    "        ax[j].set_title(f'{np.corrcoef(np.array(nn_chem_sub.neurons[str(k.name)].amplitude)[np.arange(num_timepoints)], res[k])[0,1]}')\n",
    "    # ax[j].plot(time_points, np.array(nn_chem_sub.neurons[str(k.name)].amplitude)[time_points], label=f'{k.name}-{nn_chem_sub.neurons[str(k.name)].name}', color='gray')\n",
    "    ax1 = ax[j]\n",
    "    ax1.plot(np.arange(num_timepoints), res[k], color='orange', label=f'{k.name}-{nn_chem_sub.neurons[str(k.name)].name}')\n",
    "    ax1.legend(frameon=False)\n",
    "f.suptitle(f'{database}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = '/Users/sahilmoza/Documents/Codes/CEDNe/examples/python/data_sources/downloads/Atanas_2023/Control'\n",
    "for study_name in os.listdir(f\"{root_path}\"):\n",
    "\n",
    "    DB_PATH = f'sqlite:///{root_path}/{study_name}/cedne_optimization_optuna.db'\n",
    "    study_names = optuna.study.get_all_study_names(storage=DB_PATH)\n",
    "    print(\"Available studies:\", study_names)\n",
    "    print(study_name, DB_PATH)\n",
    "    study = optuna.load_study(study_name=f'../../data_sources/downloads/Atanas_2023/Control/{study_name}', storage=DB_PATH)\n",
    "    # Extract trial data\n",
    "    trials = study.trials\n",
    "    trial_numbers = [t.number for t in trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    loss_values = [t.value for t in trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    \n",
    "    # Plot loss over trials\n",
    "    f, ax = plt.subplots(figsize=(5,3))\n",
    "    ax.plot(trial_numbers, loss_values, marker=\"o\", linestyle=\"-\", color=\"gray\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_xlabel(\"Trial Number\")\n",
    "    ax.set_ylabel(\"Log Loss\")\n",
    "    ax.set_title(f\"{study_name} Loss over Trials\")\n",
    "    utils.simpleaxis(ax)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "root_path = '/Users/sahilmoza/Documents/Codes/CEDNe/examples/python/data_sources/downloads/Atanas_2023/Control'\n",
    "for study_name in os.listdir(f\"{root_path}\"):\n",
    "    DB_PATH = f'sqlite:///{root_path}/{study_name}/cedne_optimization_optuna.db'\n",
    "    # Load study from database\n",
    "    print(study_name, DB_PATH)\n",
    "    study = optuna.load_study(study_name=f'../../data_sources/downloads/Atanas_2023/Control/{study_name}', storage=DB_PATH)\n",
    "    # Extract trial data\n",
    "    best_params[study_name] = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = []\n",
    "for study in best_params:\n",
    "    all_keys.append(best_params[study].keys())\n",
    "all_keys = set(all_keys[0]).union(*all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_list = {}\n",
    "tconst_list = {}\n",
    "base_list = {}\n",
    "weight_list = {}\n",
    "for j,key in enumerate(all_keys):\n",
    "    pref = key.split(\":\")[0]\n",
    "    if pref == 'gain':\n",
    "        suff = key.split(\":\")[1]\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            if key in best_params[study]:\n",
    "                paramlist.append(best_params[study][key])\n",
    "        gain_list[suff] = paramlist\n",
    "    elif pref == 'time_constant':\n",
    "        suff = key.split(\":\")[1]\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            if key in best_params[study]:\n",
    "                paramlist.append(best_params[study][key])\n",
    "        tconst_list[suff] = paramlist\n",
    "    elif pref == 'baseline':\n",
    "        suff = key.split(\":\")[1]\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            if key in best_params[study]:\n",
    "                paramlist.append(best_params[study][key])\n",
    "        base_list[suff] = paramlist\n",
    "    elif pref == 'weight':\n",
    "        suff = '->'.join(key.split(\":\")[1:-1])\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            if key in best_params[study]:\n",
    "                paramlist.append(best_params[study][key])\n",
    "        weight_list[suff] = paramlist\n",
    "    else:\n",
    "        print(f\"Unknown parameter: {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your Optuna SQLite database\n",
    "CEDNE_ROOT = os.path.dirname(os.path.abspath(cedne.__file__))\n",
    "PACKAGE_ROOT = CEDNE_ROOT.split('src')[0]\n",
    "\n",
    "for study_name in os.listdir(f\"{PACKAGE_ROOT}/tmp\"):\n",
    "    if study_name.startswith(\"Atanas\"):        \n",
    "        DB_PATH = f\"sqlite:///{PACKAGE_ROOT}/tmp/{study_name}/cedne_optimization_optuna.db\"  # Replace with your database path\n",
    "         # Load study from database\n",
    "        print(study_name, DB_PATH)\n",
    "        study = optuna.load_study(study_name=study_name, storage=DB_PATH)\n",
    "        # Extract trial data\n",
    "        trials = study.trials\n",
    "        trial_numbers = [t.number for t in trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "        loss_values = [t.value for t in trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "        # Plot loss over trials\n",
    "        f, ax = plt.subplots(figsize=(5,3))\n",
    "        ax.plot(trial_numbers, loss_values, marker=\"o\", linestyle=\"-\", color=\"gray\")\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_xlabel(\"Trial Number\")\n",
    "        ax.set_ylabel(\"Log Loss\")\n",
    "        ax.set_title(f\"{study_name} Loss over Trials\")\n",
    "        utils.simpleaxis(ax)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "for study_name in os.listdir(f\"{PACKAGE_ROOT}/tmp\"):\n",
    "    if study_name.startswith(\"Atanas\"):        \n",
    "        DB_PATH = f\"sqlite:///{PACKAGE_ROOT}/tmp/{study_name}/cedne_optimization_optuna.db\"  # Replace with your database path\n",
    "         # Load study from database\n",
    "        print(study_name, DB_PATH)\n",
    "        study = optuna.load_study(study_name=study_name, storage=DB_PATH)\n",
    "        # Extract trial data\n",
    "        best_params[study_name] = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = []\n",
    "for study in best_params:\n",
    "    all_keys.append(best_params[study].keys())\n",
    "\n",
    "common_keys = set(all_keys[0]).intersection(*all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_list = {}\n",
    "tconst_list = {}\n",
    "base_list = {}\n",
    "weight_list = {}\n",
    "for j,key in enumerate(common_keys):\n",
    "    pref = key.split(\":\")[0]\n",
    "    if pref == 'gain':\n",
    "        suff = key.split(\":\")[1]\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            paramlist.append(best_params[study][key])\n",
    "        gain_list[suff] = paramlist\n",
    "    elif pref == 'time_constant':\n",
    "        suff = key.split(\":\")[1]\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            paramlist.append(best_params[study][key])\n",
    "        tconst_list[suff] = paramlist\n",
    "    elif pref == 'baseline':\n",
    "        suff = key.split(\":\")[1]\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            paramlist.append(best_params[study][key])\n",
    "        base_list[suff] = paramlist\n",
    "    elif pref == 'weight':\n",
    "        suff = '->'.join(key.split(\":\")[1:-1])\n",
    "        paramlist = []\n",
    "        for study in best_params:\n",
    "            paramlist.append(best_params[study][key])\n",
    "        weight_list[suff] = paramlist\n",
    "    else:\n",
    "        print(f\"Unknown parameter: {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(60, 3), layout='constrained')\n",
    "for j,key in enumerate(sorted(gain_list.keys())):\n",
    "    ax.scatter([j]*len(gain_list[key]), gain_list[key], color='gray', alpha=0.2)\n",
    "    ax.errorbar([j], y= np.mean(gain_list[key]), yerr=np.std(gain_list[key]), color='k', alpha=1, fmt='o')\n",
    "ax.set_xticks(range(len(gain_list)))\n",
    "ax.set_xticklabels(sorted(gain_list.keys()), rotation=45, fontsize='xx-large', ha='right')\n",
    "ax.tick_params(axis='y', labelsize='xx-large')\n",
    "utils.simpleaxis(ax)\n",
    "f.suptitle('Gain', fontsize='xx-large')\n",
    "plt.show()\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(60, 3), layout='constrained')\n",
    "for j,key in enumerate(sorted(tconst_list.keys())):\n",
    "    ax.scatter([j]*len(tconst_list[key]), tconst_list[key], color='gray', alpha=0.2)\n",
    "    ax.errorbar([j], y= np.mean(tconst_list[key]), yerr=np.std(tconst_list[key]), color='k', alpha=1, fmt='o')\n",
    "ax.set_xticks(range(len(tconst_list)))\n",
    "ax.set_xticklabels(sorted(tconst_list.keys()), rotation=45, fontsize='xx-large', ha='right')\n",
    "ax.tick_params(axis='y', labelsize='xx-large')\n",
    "utils.simpleaxis(ax)\n",
    "f.suptitle('Time Constant', fontsize='xx-large')\n",
    "plt.show()\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(60, 3), layout='constrained')\n",
    "for j,key in enumerate(sorted(base_list.keys())):\n",
    "    ax.scatter([j]*len(base_list[key]), base_list[key], color='gray', alpha=0.2)\n",
    "    ax.errorbar([j], y= np.mean(base_list[key]), yerr=np.std(base_list[key]), color='k', alpha=1, fmt='o')\n",
    "ax.set_xticks(range(len(base_list)))\n",
    "ax.set_xticklabels(sorted(base_list.keys()), rotation=45, fontsize='xx-large', ha='right')\n",
    "ax.tick_params(axis='y', labelsize='xx-large')\n",
    "utils.simpleaxis(ax)\n",
    "f.suptitle('Baseline', fontsize='xx-large')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_val = 1\n",
    "rowwise = {}\n",
    "nrows = len(weight_list.keys())//100+1\n",
    "f, ax = plt.subplots(nrows, 1, figsize=(60, 3*nrows), layout='constrained')\n",
    "for j,key in enumerate(sorted(weight_list.keys())):\n",
    "    if not j//100 in rowwise:\n",
    "        rowwise[j//100] = []\n",
    "    ax[j//100].scatter([j%100]*len(weight_list[key]), weight_list[key], color='gray', alpha=0.2)\n",
    "    if np.mean(weight_list[key])>thres_val:\n",
    "        ax[j//100].errorbar([j%100], y= np.mean(weight_list[key]), yerr=np.std(weight_list[key]), color='orange', alpha=1, fmt='o')\n",
    "    elif np.mean(weight_list[key])<-thres_val:\n",
    "        ax[j//100].errorbar([j%100], y= np.mean(weight_list[key]), yerr=np.std(weight_list[key]), color='purple', alpha=1, fmt='o')\n",
    "    else:\n",
    "        ax[j//100].errorbar([j%100], y= np.mean(weight_list[key]), yerr=np.std(weight_list[key]), color='k', alpha=1, fmt='o')\n",
    "    rowwise[j//100].append(key)\n",
    "\n",
    "for key in rowwise:\n",
    "    ax[key].axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax[key].set_xticks(range(len(rowwise[key])))\n",
    "    ax[key].set_xticklabels(rowwise[key], rotation=45, fontsize='xx-large', ha='right')\n",
    "    # ax[key].set_yticklabels(ax[key].get_yticks(), fontsize='xx-large')\n",
    "    utils.simpleaxis(ax[key])\n",
    "    ax[key].tick_params(axis='y', labelsize='xx-large')\n",
    "f.suptitle('Weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres_val = 1\n",
    "rowwise = {}\n",
    "nrows = len(weight_list.keys())//100+1\n",
    "f, ax = plt.subplots(nrows, 1, figsize=(60, 3*nrows), layout='constrained')\n",
    "for j,(key,val) in enumerate(sorted(weight_list.items(),key= lambda x: x[0].split('->')[1])):\n",
    "    if not j//100 in rowwise:\n",
    "        rowwise[j//100] = []\n",
    "    ax[j//100].scatter([j%100]*len(weight_list[key]), weight_list[key], color='gray', alpha=0.2)\n",
    "    if np.mean(weight_list[key])>thres_val:\n",
    "        ax[j//100].errorbar([j%100], y= np.mean(weight_list[key]), yerr=np.std(weight_list[key]), color='orange', alpha=1, fmt='o')\n",
    "    elif np.mean(weight_list[key])<-thres_val:\n",
    "        ax[j//100].errorbar([j%100], y= np.mean(weight_list[key]), yerr=np.std(weight_list[key]), color='purple', alpha=1, fmt='o')\n",
    "    else:\n",
    "        ax[j//100].errorbar([j%100], y= np.mean(weight_list[key]), yerr=np.std(weight_list[key]), color='k', alpha=1, fmt='o')\n",
    "    rowwise[j//100].append(key)\n",
    "\n",
    "for key in rowwise:\n",
    "    ax[key].axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax[key].set_xticks(range(len(rowwise[key])))\n",
    "    ax[key].set_xticklabels(rowwise[key], rotation=45, fontsize='xx-large', ha='right')\n",
    "    # ax[key].set_yticklabels(ax[key].get_yticks(), fontsize='xx-large')\n",
    "    utils.simpleaxis(ax[key])\n",
    "    ax[key].tick_params(axis='y', labelsize='xx-large')\n",
    "f.suptitle('Weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulating the best parameter models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = {}\n",
    "for study_name in best_params.keys():\n",
    "    nrs = []\n",
    "    params = best_params[study_name]\n",
    "    for key in params.keys():\n",
    "        if key.startswith('weight'):\n",
    "            _, n1, n2, _ = key.split(':')\n",
    "            nrs.append(n1)\n",
    "            nrs.append(n2)\n",
    "            nrs = list(set(nrs))\n",
    "    neurons[study_name] = nrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_parameters(params):\n",
    "    parsed_params = {}\n",
    "    for key in params.keys():\n",
    "        if key.startswith('gain'):\n",
    "            _, n = key.split(':')\n",
    "            if 'gain' not in parsed_params:\n",
    "                parsed_params['gain'] = {}\n",
    "            parsed_params['gain'][n] = params[key]\n",
    "        elif key.startswith('time_constant'):\n",
    "            _, n = key.split(':')\n",
    "            if 'time_constant' not in parsed_params:\n",
    "                parsed_params['time_constant'] = {}\n",
    "            parsed_params['time_constant'][n] = params[key]\n",
    "        elif key.startswith('baseline'):\n",
    "            _, n = key.split(':')\n",
    "            if 'baseline' not in parsed_params:\n",
    "                parsed_params['baseline'] = {}\n",
    "            parsed_params['baseline'][n] = params[key]\n",
    "        elif key.startswith('weight'):\n",
    "            _, n1, n2, _ = key.split(':')\n",
    "            if 'weight' not in parsed_params:\n",
    "                parsed_params['weight'] = {}\n",
    "            parsed_params['weight'][(n1,n2)] = params[key]\n",
    "    return parsed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = {}\n",
    "for js in os.listdir('/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/'):\n",
    "    with open (\"/Users/sahilmoza/Documents/Postdoc/Yun Zhang/data/SteveFlavell-NeuroPAL-Cell/Control/{}\".format(js), 'r') as f:\n",
    "        jsons[js+'_100_50_25'] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = utils.makeWorm(chem_only=True)\n",
    "nn_chem = w.networks[\"Neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measuredNeurons = {}\n",
    "optim_neurs = {js:[] for js in jsons.keys()}\n",
    "for js, p in jsons.items():\n",
    "    sortedKeys = sorted ([int(x) for x in (p['labeled'].keys())])\n",
    "    labelledNeurons = {p['labeled'][str(x)]['label']:x for x in sortedKeys if not '?' in p['labeled'][str(x)]['label']} # Removing unsure hits\n",
    "    measuredNeurons[js] = {m:i for i,m in enumerate(set(labelledNeurons))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datab_in, database in enumerate(jsons.keys()):\n",
    "    nn_chem_sub = nn_chem.subnetwork(neuron_names=neurons[database])\n",
    "    for neuron in nn_chem_sub.neurons:\n",
    "        if neuron in neurons[database]:\n",
    "            nn_chem_sub.neurons[neuron].set_property('amplitude', jsons[database]['trace_array'][measuredNeurons[database][neuron]])\n",
    "\n",
    "    num_timepoints = len(jsons[database]['trace_array'][measuredNeurons[database][list(measuredNeurons[database].keys())[0]]])\n",
    "    input_nodes = [nn_chem_sub.neurons[n] for n in nn_chem_sub.neurons if nn_chem_sub.neurons[n].type == 'sensory']\n",
    "    inputs = []\n",
    "    time_points = np.arange(num_timepoints)\n",
    "    for inp in input_nodes:\n",
    "        if hasattr(inp, 'amplitude'):\n",
    "            input_value = {t:inp.amplitude[j] for j,t in enumerate(time_points)}\n",
    "            inputs.append(simulator.TimeSeriesInput([inp], input_value))\n",
    "\n",
    "    params = parse_parameters(best_params[database])\n",
    "\n",
    "    baseline = {nn_chem_sub.neurons[n]:0 for n in nn_chem_sub.neurons}\n",
    "    gains = {nn_chem_sub.neurons[n]:1 for n in nn_chem_sub.neurons}\n",
    "    time_constants = {nn_chem_sub.neurons[n]:1 for n in nn_chem_sub.neurons}\n",
    "    weights = {(nn_chem_sub.neurons[e[0].name], nn_chem_sub.neurons[e[1].name]):1 for e in nn_chem_sub.edges}\n",
    "\n",
    "    baseline.update({nn_chem_sub.neurons[n]:v for n,v in params['baseline'].items()})\n",
    "    gains.update({nn_chem_sub.neurons[n]:v for n,v in params['gain'].items()})\n",
    "    time_constants.update({nn_chem_sub.neurons[n]:v for n,v in params['time_constant'].items()})\n",
    "    weights.update({(nn_chem_sub.neurons[e[0]],nn_chem_sub.neurons[e[1]]):v for e,v in params['weight'].items()})\n",
    "    \n",
    "    rate_model = simulator.RateModel(nn_chem_sub, input_nodes, weights, gains, time_constants, baseline, static_neurons=input_nodes, \\\n",
    "                                            time_points=time_points, inputs=inputs)\n",
    "    rate_model.time_points = time_points\n",
    "    res = rate_model.simulate()\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10,2*len(res.keys())), nrows=len(res.keys()), sharex=True, layout='constrained')\n",
    "    # for k, (n, node) in enumerate(nodelist):\n",
    "    for j,k in enumerate(res.keys()):\n",
    "        utils.simpleaxis(ax[j])\n",
    "        if hasattr(nn_chem_sub.neurons[str(k.name)], 'amplitude'):\n",
    "            ax[j].plot(np.arange(num_timepoints), np.array(nn_chem_sub.neurons[str(k.name)].amplitude), color='gray')\n",
    "            ax[j].set_title(f'{np.corrcoef(np.array(nn_chem_sub.neurons[str(k.name)].amplitude)[np.arange(num_timepoints)], res[k])[0,1]}')\n",
    "        # ax[j].plot(time_points, np.array(nn_chem_sub.neurons[str(k.name)].amplitude)[time_points], label=f'{k.name}-{nn_chem_sub.neurons[str(k.name)].name}', color='gray')\n",
    "        ax1 = ax[j]\n",
    "        ax1.plot(np.arange(num_timepoints), res[k], color='orange', label=f'{k.name}-{nn_chem_sub.neurons[str(k.name)].name}')\n",
    "        ax1.legend(frameon=False)\n",
    "    f.suptitle(f'{database}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in rate_model.neurons:\n",
    "    print(n.name, n.type, rate_model.neurons[n].baseline, rate_model.neurons[n].gain, rate_model.neurons[n].time_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edata in rate_model.edges(data=True, keys=True):\n",
    "    print(edata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in nn_chem_sub.edges:\n",
    "    print(weights[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.loadSynapticWeights(nn_chem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leifer_weight = {}\n",
    "for key in weight_list.keys():\n",
    "    n1,n2 = key.split('->')\n",
    "    c = nn_chem.connections[(nn_chem.neurons[n1], nn_chem.neurons[n2],0)]\n",
    "    leifer_weight[key] = c.weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_w = []\n",
    "leifer_w = []\n",
    "thres_val = 0.2\n",
    "for key in weight_list.keys():\n",
    "    if np.abs(leifer_weight[key])>thres_val and np.abs(np.mean(weight_list[key]))>thres_val:\n",
    "        leifer_w.append(leifer_weight[key])\n",
    "        fit_w.append(np.mean(weight_list[key]))\n",
    "fit_w , leifer_w = np.array(fit_w), np.array(leifer_w)\n",
    "f, ax = plt.subplots(figsize=(3,3))\n",
    "ax.scatter(np.abs(fit_w), np.abs(leifer_w), color='gray', alpha=1)\n",
    "slope, intercept, r_value, p_value, std_err = ss.linregress(np.abs(fit_w), np.abs(leifer_w))\n",
    "x = np.linspace(0,2,100)\n",
    "ax.plot(x, slope*x+intercept, color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_w = [item for sublist in weight_list.values() for item in sublist]\n",
    "flat_gain = [item for sublist in gain_list.values() for item in sublist]\n",
    "flat_tconst = [item for sublist in tconst_list.values() for item in sublist]\n",
    "flat_base = [item for sublist in base_list.values() for item in sublist]\n",
    "\n",
    "plt.hist(flat_w)\n",
    "plt.title('Weights')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(flat_gain)\n",
    "plt.title('Gains')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(flat_tconst)\n",
    "plt.title('Time Constants')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(flat_base)\n",
    "plt.title('Baselines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*len(gain_list) + len(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "for study_name in os.listdir(f\"{PACKAGE_ROOT}/tmp\"):\n",
    "    if study_name.startswith(\"Atanas\"):        \n",
    "        DB_PATH = f\"sqlite:///{PACKAGE_ROOT}/tmp/{study_name}/cedne_optimization_optuna.db\"  # Replace with your database path\n",
    "         # Load study from database\n",
    "        print(study_name, DB_PATH)\n",
    "        study = optuna.load_study(study_name=study_name, storage=DB_PATH)\n",
    "        # Extract trial data\n",
    "        data_trials = np.array([list(trial.params.values()) for trial in study.trials if trial.value is not None])\n",
    "        pca = PCA().fit(data_trials)\n",
    "        explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "        # Plot the variance explained by each principal component\n",
    "        plt.plot(range(1, len(explained_variance)+1), explained_variance, marker='o')\n",
    "        plt.xlabel(\"Number of Principal Components\")\n",
    "        plt.ylabel(\"Cumulative Explained Variance\")\n",
    "        plt.title(\"Effective Dimensionality of Optimized Parameters\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
